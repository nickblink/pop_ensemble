{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Admin-Dell\\anaconda3\\lib\\site-packages\\gpflow\\experimental\\utils.py:42: UserWarning: You're calling gpflow.experimental.check_shapes.decorator.check_shapes which is considered *experimental*. Expect: breaking changes, poor documentation, and bugs.\n",
      "  warn(\n",
      "C:\\Users\\Admin-Dell\\anaconda3\\lib\\site-packages\\gpflow\\experimental\\utils.py:42: UserWarning: You're calling gpflow.experimental.check_shapes.inheritance.inherit_check_shapes which is considered *experimental*. Expect: breaking changes, poor documentation, and bugs.\n",
      "  warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow version: 2.11.0. Expected: 2.7.0\n",
      "TensorFlow Probability version: 0.19.0. Expected: 0.15.0\n"
     ]
    }
   ],
   "source": [
    "from wrapper_functions_CAR import *\n",
    "tf.config.run_functions_eagerly(True)\n",
    "np.random.seed(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create the fake data\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "training2010 = pd.read_csv('../data/merged_wp_census_data2_081122.csv')\n",
    "county_adj = pd.read_csv('../data/countyadj2.csv', index_col = 0)\n",
    "#models = ['acs', 'pep', 'worldpop']\n",
    "models = ['acs', 'pep']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_NY, adj_NY = subset_data_by_state(training2010, county_adj, 'New York', 'NY')\n",
    "#phi_true, u_true, data = simulate_data(data_NY, adj_NY, pivot = -1, sim_numbers = True, one_model = False, models = models)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "U-Nmbq-0wgYy"
   },
   "source": [
    "# Default Configs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "fY1Z6ccs2XUP"
   },
   "outputs": [],
   "source": [
    "# MCMC configs.\n",
    "mcmc_step_size=0.1 # @param\n",
    "mcmc_sample_size=500 # @param\n",
    "mcmc_num_steps=10_000 # @param\n",
    "mcmc_burnin=2_500 # @param\n",
    "mcmc_nchain=10 # @param\n",
    "mcmc_seed=0 # @param\n",
    "\n",
    "DEFAULT_MCMC_CONFIG = dict(step_size=mcmc_step_size, \n",
    "                           num_steps=mcmc_sample_size, \n",
    "                           burnin=mcmc_burnin, \n",
    "                           nchain=mcmc_nchain, \n",
    "                           seed=mcmc_seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Running with HMC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mcmc_config = DEFAULT_MCMC_CONFIG.copy()\n",
    "mcmc_config.update(dict(burnin = 2_500, num_steps = 10_000, nchain = 5, \n",
    "                        kernel_type = 'hmc', step_adaptor_type = 'simple'))\n",
    "mcmc_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "res_dict = {}\n",
    "for pivot_DGP in range(-1, 2):\n",
    "    print('pivot DGP: ' + str(pivot_DGP))\n",
    "    \n",
    "    phi_true, u_true, data_pivot = simulate_data(data_NY[:], \n",
    "                                                 adj_NY[:], \n",
    "                                                 sim_numbers = False,\n",
    "                                                 scale_down = 1000,\n",
    "                                                 poisson_noise = True,\n",
    "                                                 pivot = pivot_DGP, \n",
    "                                                 one_model = False, \n",
    "                                                 models = models)\n",
    "    \n",
    "    for pivot_fit in range(-1, 2):\n",
    "        print('pivot fit: ' + str(pivot_fit))\n",
    "        t0 = time.perf_counter()\n",
    "        CAR_samples, chain_samples, sampler_stat = run_mcmc_CAR(data = data_pivot[:],\n",
    "                                                                adjacency = adj_NY[:],\n",
    "                                                                pivot = pivot_fit,\n",
    "                                                                models = models,                                                        \n",
    "                                                                debug_mode = True,\n",
    "                                                                **mcmc_config)  \n",
    "        print(time.perf_counter() - t0)\n",
    "        \n",
    "        res_dict['pDGP: ' + str(pivot_DGP) + '; pfit: ' + str(pivot_fit)] = [CAR_samples, chain_samples, sampler_stat, phi_true, u_true, data_pivot, pivot_DGP, pivot_fit, models]\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Saving and loading Python objects with Pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_pivot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "# using local data file because these are too big for github\n",
    "#local_dir = 'C:/Users/nickl/Dropbox/Nick_Cranston/HSPH/Research/Nethery Project/Data/'\n",
    "local_dir = 'C:/Users/Admin-Dell/Dropbox/Nick_Cranston/HSPH/Research/Nethery Project/Data/'\n",
    "with open(local_dir + 'CAR_samples_NY_n10000_realdata_div1000_2models_May152023.pickle', 'wb') as results_file:\n",
    "  pickle.dump([res_dict, mcmc_config], results_file)\n",
    "  #pickle.dump([CAR_samples, CAR_samples0, CAR_samples1, CAR_samples2, CAR_samples], results_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading results and analyzing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "local_dir = 'C:/Users/Admin-Dell/Dropbox/Nick_Cranston/HSPH/Research/Nethery Project/Data/'\n",
    "file = local_dir + 'CAR_samples_NY_n10000_realdata_2models_May152023.pickle'\n",
    "with open(file, \"rb\") as input_file:\n",
    "     #CAR_samples, chain_samples, sampler_stat, mcmc_config, phi_true, u_true, data_sub = pickle.load(input_file)\n",
    "    res_dict, mcmc_config = pickle.load(input_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_pivot[['census','acs','pep']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting the rhat and ESS values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for key in res_dict.keys():\n",
    "    sampler_stat = res_dict[key][2]\n",
    "    stepsize_vec.append(sampler_stat[0][0].numpy())\n",
    "    \n",
    "# make the data frame\n",
    "df_stepsize = pd.DataFrame(np.reshape(np.array(stepsize_vec), (4,4)), \n",
    "                       index = ['none','acs','pep','WP'], \n",
    "                       columns = ['none','acs','pep','WP'])\n",
    "df_stepsize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>none</th>\n",
       "      <th>acs</th>\n",
       "      <th>pep</th>\n",
       "      <th>WP</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>none</th>\n",
       "      <td>1.571394</td>\n",
       "      <td>9.714918e+08</td>\n",
       "      <td>9.803074e+02</td>\n",
       "      <td>1558.569214</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>acs</th>\n",
       "      <td>7.384605</td>\n",
       "      <td>3.776405e+04</td>\n",
       "      <td>7.028971e+07</td>\n",
       "      <td>5.132687</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pep</th>\n",
       "      <td>10651.396484</td>\n",
       "      <td>3.741119e+00</td>\n",
       "      <td>1.448885e+05</td>\n",
       "      <td>3.363313</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>WP</th>\n",
       "      <td>2.530257</td>\n",
       "      <td>4.024219e+00</td>\n",
       "      <td>4.721138e+01</td>\n",
       "      <td>125924.406250</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              none           acs           pep             WP\n",
       "none      1.571394  9.714918e+08  9.803074e+02    1558.569214\n",
       "acs       7.384605  3.776405e+04  7.028971e+07       5.132687\n",
       "pep   10651.396484  3.741119e+00  1.448885e+05       3.363313\n",
       "WP        2.530257  4.024219e+00  4.721138e+01  125924.406250"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Get the convergence diagnostics from model fits\n",
    "rhat_vec = []\n",
    "for key in res_dict.keys():\n",
    "    #print(key)\n",
    "    chain_samples = res_dict[key][1]\n",
    "    u_samples = phi_to_u(chain_samples, res_dict[key][7])\n",
    "    ESS = tfp.mcmc.effective_sample_size(u_samples, cross_chain_dims = 1).numpy()\n",
    "    rhat = tfp.mcmc.potential_scale_reduction(chain_samples, independent_chain_ndims=1).numpy()\n",
    "    print(np.quantile(ESS, [0.5, 0.025, 0.975]))\n",
    "    print(np.quantile(rhat, [0.5, 0.025, 0.975]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plotting the density of ensemble weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "#plt.rcParams['figure.figsize'] = [20, 10]\n",
    "plt.rcParams['figure.figsize'] = [15, 3]\n",
    "labels = models[:]\n",
    "labels.insert(0, 'none')\n",
    "\n",
    "fig = plt.figure()\n",
    "iter = 0\n",
    "\n",
    "for pivot_DGP in range(-1,0):\n",
    "    \n",
    "    iter = iter + 1\n",
    "    \n",
    "    u_true = res_dict['pDGP: ' + str(pivot_DGP) + '; pfit: -1'][4]\n",
    "    \n",
    "    CAR_df = pd.DataFrame(u_true[0,:,:], columns = models)\n",
    "    #CAR_df = pd.DataFrame(CAR_ensemble_weights.numpy(), columns = [\"acs\",\"pep\",\"worldpop\"])\n",
    "\n",
    "    #plt.subplot(3, 4, iter)\n",
    "    plt.subplot(1, 4, iter)\n",
    "    sns.set(style=\"darkgrid\")\n",
    "    tt = sns.kdeplot(CAR_df['acs'], shade=True, color=\"r\", label = 'acs')\n",
    "    tt = sns.kdeplot(CAR_df[\"pep\"], shade=True, color=\"b\", label = 'pep')\n",
    "    #tt = sns.kdeplot(CAR_df[\"worldpop\"], shade=True, color=\"g\", label = 'worldpop')\n",
    "    if pivot_DGP == -1:\n",
    "        plt.title('u true')\n",
    "    plt.ylabel(labels[pivot_DGP + 1])\n",
    "    plt.xlabel('')\n",
    "    plt.xlim(0,1)\n",
    "    \n",
    "    for pivot_fit in range(-1,2):\n",
    "        iter = iter + 1\n",
    "        key = 'pDGP: ' + str(pivot_DGP) + '; pfit: ' + str(pivot_fit)  \n",
    "\n",
    "        # get the ensemble weights\n",
    "        CAR_ensemble_phis = tf.reduce_mean(res_dict[key][0][0], axis = 2).numpy()\n",
    "        u = phi_to_u(CAR_ensemble_phis, pivot = pivot_fit)\n",
    "        CAR_df = pd.DataFrame(u, columns = models)\n",
    "\n",
    "        #plt.subplot(3, 4, iter)\n",
    "        plt.subplot(1, 4, iter)\n",
    "        sns.set(style=\"darkgrid\")\n",
    "        tt = sns.kdeplot(CAR_df['acs'], shade=True, color=\"r\", label = 'acs')\n",
    "        tt = sns.kdeplot(CAR_df[\"pep\"], shade=True, color=\"b\", label = 'pep')\n",
    "        #tt = sns.kdeplot(CAR_df[\"worldpop\"], shade=True, color=\"g\", label = 'worldpop')\n",
    "        #plt.legend()\n",
    "        plt.xlabel('')\n",
    "        plt.ylabel('')\n",
    "        if pivot_DGP == -1:\n",
    "            plt.title(labels[pivot_fit + 1])\n",
    "        plt.xlim(0,1)\n",
    "        \n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plotting scatterplots of the fitted vs true u values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "key = 'pDGP: -1; pfit: -1'\n",
    "phis = res_dict[key][0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams['figure.figsize'] = [12, 3]\n",
    "labels = models[:]\n",
    "labels.insert(0, 'none')\n",
    "\n",
    "fig = plt.figure()\n",
    "iter = 0\n",
    "\n",
    "for pivot_DGP in range(-1,0):\n",
    "    \n",
    "    ## Get the true u values\n",
    "    u_true = res_dict['pDGP: ' + str(pivot_DGP) + '; pfit: -1'][4]\n",
    "    CAR_df = pd.DataFrame(u_true[0,:,:], columns = models)\n",
    "    \n",
    "    for pivot_fit in range(-1,2):\n",
    "        iter = iter + 1\n",
    "        key = 'pDGP: ' + str(pivot_DGP) + '; pfit: ' + str(pivot_fit)    \n",
    "\n",
    "        ## get the ensemble weights\n",
    "        phi = res_dict[key][0][0]\n",
    "        \n",
    "        ## Get the u values from each run\n",
    "        u = np.empty(shape=(phi.shape[0], \n",
    "                              len(models), \n",
    "                              phi.shape[2]), \n",
    "                       dtype='float64')\n",
    "        for i in range(phi.shape[2]):\n",
    "            u[:,:,i] = phi_to_u(phi.numpy()[:,:,i], pivot = pivot_fit)   \n",
    "            \n",
    "        CAR_df = pd.DataFrame(np.mean(u, axis = 2), columns = models)\n",
    "\n",
    "        #plt.subplot(3, 4, iter)\n",
    "        plt.subplot(1, 3, iter)\n",
    "\n",
    "        x = np.ndarray.flatten(u_true[0,:,:].numpy())\n",
    "        y = np.ndarray.flatten(CAR_df.values)\n",
    "        plt.scatter(x, y)\n",
    "        plt.xlabel(\"true u\")\n",
    "        plt.ylabel(labels[pivot_fit + 1])\n",
    "\n",
    "        plt.xlim([min([min(x), min(y)]), max([max(x), max(y)])])\n",
    "        plt.ylim([min([min(x), min(y)]), max([max(x), max(y)])])\n",
    "        ax = plt.gca()\n",
    "        ax.set_aspect('equal', adjustable='box')\n",
    "\n",
    "        ## obtain m (slope) and b(intercept) of linear regression line\n",
    "        m, b = np.polyfit(x, y, 1)\n",
    "        ## add linear regression line to scatterplot \n",
    "        #plt.plot(x, m*x+b, color = 'red')\n",
    "        ## add y = x line\n",
    "        plt.plot(x, x, color = 'red')\n",
    "\n",
    "\n",
    "        from scipy.stats import pearsonr\n",
    "        pearsonr(x,y)[0]\n",
    "        \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plotting the fitted vs true y predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams['figure.figsize'] = [12, 3]\n",
    "labels = models[:]\n",
    "labels.insert(0, 'none')\n",
    "\n",
    "fig = plt.figure()\n",
    "iter = 0\n",
    "\n",
    "for pivot_DGP in range(-1,0):\n",
    "        \n",
    "    ## Get the data\n",
    "    data_pivot = res_dict['pDGP: ' + str(pivot_DGP) + '; pfit: -1'][5]\n",
    "    \n",
    "    ## Get the true u values\n",
    "    u_true = res_dict['pDGP: ' + str(pivot_DGP) + '; pfit: -1'][4]\n",
    "    CAR_df = pd.DataFrame(u_true[0,:,:], columns = models)\n",
    "    y_exp = tf.reduce_sum(data_pivot[models].values*u_true, axis = 2)[0].numpy()\n",
    "    \n",
    "    for pivot_fit in range(-1,2):\n",
    "        iter = iter + 1\n",
    "        key = 'pDGP: ' + str(pivot_DGP) + '; pfit: ' + str(pivot_fit)    \n",
    "\n",
    "        ## get the ensemble weights\n",
    "        phi = res_dict[key][0][0]\n",
    "        \n",
    "        ## Get the u values from each run\n",
    "        predictions = np.empty(shape=(phi.shape[0], \n",
    "                              phi.shape[2]), \n",
    "                       dtype='float64')\n",
    "        for i in range(phi.shape[2]):\n",
    "            u = phi_to_u(phi.numpy()[:,:,i], pivot = pivot_fit)   \n",
    "            predictions[:,i] = tf.reduce_sum(data_pivot[models].values*u, axis = 1)\n",
    "    \n",
    "        y_pred = np.mean(predictions, axis = 1)\n",
    "            \n",
    "        #CAR_df = pd.DataFrame(np.mean(u, axis = 2), columns = models)\n",
    "\n",
    "        #plt.subplot(3, 4, iter)\n",
    "        plt.subplot(1, 3, iter)\n",
    "\n",
    "        x = data_pivot['census']\n",
    "        y = y_pred\n",
    "        #y = y_pred.numpy()\n",
    "        plt.scatter(x, y)\n",
    "        plt.xlabel(\"true census values\")\n",
    "        plt.ylabel(labels[pivot_fit + 1])\n",
    "\n",
    "        #obtain m (slope) and b(intercept) of linear regression line\n",
    "        m, b = np.polyfit(x, y.astype('float64'), 1)\n",
    "\n",
    "        plt.xlim([min([min(x), min(y)]), max([max(x), max(y)])])\n",
    "        plt.ylim([min([min(x), min(y)]), max([max(x), max(y)])])\n",
    "        ax = plt.gca()\n",
    "        ax.set_aspect('equal', adjustable='box')\n",
    "        ax.set_xscale(\"log\")\n",
    "        ax.set_yscale(\"log\")\n",
    "\n",
    "        ## obtain m (slope) and b(intercept) of linear regression line\n",
    "        m, b = np.polyfit(x, y, 1)\n",
    "        ## add linear regression line to scatterplot \n",
    "        #plt.plot(x, m*x+b, color = 'red')\n",
    "        ## add y = x line\n",
    "        plt.plot(x, x, color = 'red')\n",
    "        \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plotting the chloroploth maps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the weights dict for plotting the outcomes\n",
    "\n",
    "weights_dict = {\n",
    "    \"acs\": CAR_ensemble_weights[:,0],\n",
    "    \"pep\": CAR_ensemble_weights[:,1],\n",
    "    \"worldpop\": CAR_ensemble_weights[:,2]\n",
    "}\n",
    "\n",
    "color_weights = make_color_norm(\n",
    "    list(weights_dict.values())[1],   \n",
    "    method=\"percentile\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "norm_weights_dict = {\n",
    "    \"acs\": u[:,0],\n",
    "    \"pep\": u[:,1],\n",
    "    \"worldpop\": u[:,2]\n",
    "}\n",
    "\n",
    "color_norm_weights = make_color_norm(\n",
    "    list(norm_weights_dict.values())[1],   \n",
    "    method=\"percentile\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly\n",
    "from urllib.request import urlopen\n",
    "import json\n",
    "with urlopen('https://raw.githubusercontent.com/plotly/datasets/master/geojson-counties-fips.json') as response:\n",
    "    counties = json.load(response)\n",
    "\n",
    "import pandas as pd\n",
    "# df = pd.read_csv(\"https://raw.githubusercontent.com/plotly/datasets/master/fips-unemp-16.csv\",\n",
    "#                    dtype={\"fips\": str})\n",
    "import matplotlib.colors as colors\n",
    "\n",
    "import plotly.express as px"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for model_name in models:\n",
    "    output = pd.DataFrame(np.column_stack([data_sub[[\"GEOID\"]], weights_dict[model_name]]))\n",
    "    output = output.set_axis(['GEOID', model_name], axis=1)\n",
    "    output[model_name] = output[model_name].astype(float)\n",
    "    fig = px.choropleth_mapbox(output, geojson=counties, locations='GEOID', color=model_name,\n",
    "                           color_continuous_scale=\"Viridis\",\n",
    "                           #range_color=(0.05,0.07),\n",
    "                           mapbox_style=\"carto-positron\",\n",
    "                           #mapbox_style='white-bg',\n",
    "                           #featureidkey=\"properties.MWS_ID\",\n",
    "                           zoom=3, center = {\"lat\": 37.0902, \"lon\": -95.7129},\n",
    "                           opacity=0.5#,\n",
    "                           #labels={'unemp':'unemployment rate'}\n",
    "                          )\n",
    "    fig.update_layout(margin={\"r\":0,\"t\":0,\"l\":0,\"b\":0})\n",
    "    fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pd.concat([data_NY[[\"GEOID\"]].reset_index(drop=True), pd.DataFrame( phi_true[0].numpy(), columns = models)], axis=1)\n",
    "# pd.DataFrame( phi_true[0].numpy(), columns = models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_phi = pd.concat([data_sub[[\"GEOID\"]].reset_index(drop=True), \n",
    "                         pd.DataFrame(phi_true[0].numpy(), columns = models)], \n",
    "                        axis=1)\n",
    "\n",
    "full_u = pd.concat([data_sub[[\"GEOID\"]].reset_index(drop=True), \n",
    "                         pd.DataFrame(u_true[0].numpy(), columns = models)], \n",
    "                        axis=1)\n",
    "\n",
    "\n",
    "#full_phi[['GEOID', 'acs']], full_u"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for model_name in models:\n",
    "    output = full_phi[['GEOID', model_name]]\n",
    "    fig = px.choropleth_mapbox(output, geojson=counties, locations='GEOID', color=model_name,\n",
    "                           color_continuous_scale=\"Viridis\",\n",
    "                           #range_color=(0.05,0.07),\n",
    "                           mapbox_style=\"carto-positron\",\n",
    "                           #mapbox_style='white-bg',\n",
    "                           #featureidkey=\"properties.MWS_ID\",\n",
    "                           zoom=3, center = {\"lat\": 37.0902, \"lon\": -95.7129},\n",
    "                           opacity=0.5#,\n",
    "                           #labels={'unemp':'unemployment rate'}\n",
    "                          )\n",
    "    fig.update_layout(margin={\"r\":0,\"t\":0,\"l\":0,\"b\":0})\n",
    "    fig.show()"
   ]
  }
 ],
 "metadata": {
  "@webio": {
   "lastCommId": null,
   "lastKernelId": null
  },
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [
    "FyVOAW4EODnT",
    "ebzyBOEoNQ_a",
    "vAgjEq1-dty-"
   ],
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
