{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-10-18 12:00:20.153299: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "/Users/liyanran/opt/anaconda3/envs/BNE/lib/python3.7/site-packages/gpflow/experimental/utils.py:43: UserWarning: You're calling gpflow.experimental.check_shapes.decorator.check_shapes which is considered *experimental*. Expect: breaking changes, poor documentation, and bugs.\n",
      "  f\"You're calling {name} which is considered *experimental*.\"\n",
      "/Users/liyanran/opt/anaconda3/envs/BNE/lib/python3.7/site-packages/gpflow/experimental/utils.py:43: UserWarning: You're calling gpflow.experimental.check_shapes.inheritance.inherit_check_shapes which is considered *experimental*. Expect: breaking changes, poor documentation, and bugs.\n",
      "  f\"You're calling {name} which is considered *experimental*.\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow version: 2.10.0. Expected: 2.7.0\n",
      "TensorFlow Probability version: 0.18.0. Expected: 0.15.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-10-18 12:00:51.049855: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "from wrapper_functions import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read in Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "training2010 = pd.read_csv('../data/merged_fb_census_data_280922.csv')\n",
    "coordinate = np.asarray(training2010[[\"lon\", \"lat\"]].values.tolist()).astype(np.float32)\n",
    "training2010=training2010.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([3108, 4])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TensorShape([3108, 4])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2010 center and scale:  [-90.83139   37.882298] [124.135445  48.820534]\n"
     ]
    }
   ],
   "source": [
    "models = ['acs', 'pep', 'worldpop','fb']\n",
    "# base_preds_train = tf.stack([training2010[m] for m in models], axis=-1).astype(np.float32)\n",
    "# base_preds_test = tf.stack([training2010[m] for m in models], axis=-1).astype(np.float32)\n",
    "\n",
    "\n",
    "# standardize\n",
    "X_train1 = np.asarray(training2010[[\"lon\", \"lat\"]].values.tolist()).astype(np.float32)\n",
    "X_test1 = np.asarray(training2010[[\"lon\", \"lat\"]].values.tolist()).astype(np.float32)\n",
    "X_valid = np.concatenate((X_train1, X_test1), axis=0)\n",
    "X_centr = np.nanmean(X_valid, axis=0)\n",
    "X_scale = np.nanmax(X_valid, axis=0) - np.nanmin(X_valid, axis=0)\n",
    "\n",
    "X_train1 = (X_train1 - X_centr) / X_scale\n",
    "X_test1 = (X_test1 - X_centr) / X_scale\n",
    "\n",
    "Y_train = np.expand_dims(training2010[\"census\"], 1).astype(np.float32)\n",
    "\n",
    "Y_test = np.expand_dims(training2010[\"census\"], 1).astype(np.float32)\n",
    "\n",
    "base_preds_train = tf.stack([training2010[m].astype(np.float32) for m in models], axis=-1)\n",
    "base_preds_test = tf.stack([training2010[m].astype(np.float32) for m in models], axis=-1)\n",
    "display(base_preds_train.shape, base_preds_test.shape)\n",
    "\n",
    "\n",
    "print(\"2010 center and scale: \", X_centr, X_scale)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.03371918, -0.10942537],\n",
       "       [ 0.02501395, -0.14633153],\n",
       "       [ 0.04377531, -0.12306847],\n",
       "       ...,\n",
       "       [-0.15887196,  0.06978671],\n",
       "       [-0.13572185,  0.12344731],\n",
       "       [-0.11056888,  0.12210351]], dtype=float32)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X, y = np.asarray(training2010[[\"lon\", \"lat\"]].values.tolist()).astype(np.float32),np.asarray(training2010[\"census\"]).astype(np.float32)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.8, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "U-Nmbq-0wgYy"
   },
   "source": [
    "# Default Configs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "zCuDvZJ71_Dz"
   },
   "outputs": [],
   "source": [
    "# GP configs.\n",
    "y_noise_std = 0.1  # @param\n",
    "hidden_units = 128  # @param\n",
    "lengthscale=1.  # @param\n",
    "l2_regularizer=0.1  # @param\n",
    "\n",
    "DEFAULT_GP_CONFIG = dict(lengthscale=lengthscale,\n",
    "                         l2_regularizer=l2_regularizer, \n",
    "                         hidden_units=hidden_units, \n",
    "                         y_noise_std=y_noise_std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "fY1Z6ccs2XUP"
   },
   "outputs": [],
   "source": [
    "# BNE model configs.\n",
    "estimate_mean = \"True\" # @param [\"True\", \"False\"]\n",
    "estimate_variance = \"False\" # @param [\"True\", \"False\"]\n",
    "estimate_skewness = \"False\" # @param [\"True\", \"False\"]\n",
    "variance_prior_mean=0. # @param\n",
    "skewness_prior_mean=0. # @param\n",
    "\n",
    "estimate_mean = eval(estimate_mean)\n",
    "estimate_variance = eval(estimate_variance)\n",
    "estimate_skewness = eval(estimate_skewness)\n",
    "\n",
    "DEFAULT_BNE_CONFIG = dict(estimate_mean=estimate_mean,\n",
    "                          estimate_variance=estimate_variance,\n",
    "                          estimate_skewness=estimate_skewness,\n",
    "                          variance_prior_mean=variance_prior_mean,\n",
    "                          skewness_prior_mean=skewness_prior_mean)\n",
    "\n",
    "# MAP configs.\n",
    "map_step_size=0.1 # @param\n",
    "map_num_steps=10_000 # @param\n",
    "\n",
    "DEFAULT_MAP_CONFIG = dict(learning_rate=map_step_size,\n",
    "                          num_steps=map_num_steps)\n",
    "\n",
    "# MCMC configs.\n",
    "mcmc_step_size=0.1 # @param\n",
    "mcmc_sample_size=500 # @param\n",
    "mcmc_num_steps=10_000 # @param\n",
    "mcmc_burnin=2_500 # @param\n",
    "mcmc_nchain=10 # @param\n",
    "mcmc_seed=0 # @param\n",
    "\n",
    "DEFAULT_MCMC_CONFIG = dict(step_size=mcmc_step_size, \n",
    "                           num_steps=mcmc_sample_size, \n",
    "                           burnin=mcmc_burnin, \n",
    "                           nchain=mcmc_nchain, \n",
    "                           seed=mcmc_seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model configs.\n",
    "y_noise_std = 0.1  # @param\n",
    "lengthscale=1.  # @param\n",
    "l2_regularizer=0.1  # @param\n",
    "\n",
    "# MCMC configs.\n",
    "map_step_size=0.1 # @param\n",
    "map_num_steps=10_000 # @param\n",
    "\n",
    "mcmc_step_size=0.1 # @param\n",
    "mcmc_num_steps=10_000 # @param\n",
    "\n",
    "# Posterior configs.\n",
    "bma_n_samples_train = 100 # @param\n",
    "bma_n_samples_test = 200 # @param\n",
    "bma_n_samples_eval = 1000  # @param\n",
    "\n",
    "bma_seed = 0  # @param\n",
    "bne_seed = 0 # @param\n",
    "\n",
    "# Assemble into configs.\n",
    "bma_model_config = DEFAULT_GP_CONFIG.copy()\n",
    "map_config = DEFAULT_MAP_CONFIG.copy()\n",
    "mcmc_config = DEFAULT_MCMC_CONFIG.copy()\n",
    "\n",
    "bma_model_config.update(dict(lengthscale=lengthscale,\n",
    "                             l2_regularizer=l2_regularizer,\n",
    "                             y_noise_std=y_noise_std))\n",
    "\n",
    "map_config.update(dict(learning_rate=map_step_size,\n",
    "                       num_steps=map_num_steps))\n",
    "\n",
    "mcmc_config.update(dict(step_size=mcmc_step_size, \n",
    "                        num_steps=mcmc_num_steps))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZHthi3uPKLkr"
   },
   "source": [
    "### Model Configs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "KDl4Di8lKIgm"
   },
   "outputs": [],
   "source": [
    "# Optimization configs. \n",
    "# Consider reduce below parameters / set to `False` if MCMC is taking too long:\n",
    "# mcmc_num_steps, mcmc_burnin, mcmc_nchain, mcmc_initialize_from_map.\n",
    "map_step_size=5e-4   # @param\n",
    "map_num_steps=10_000  # @param\n",
    "\n",
    "mcmc_step_size=1e-4 # @param\n",
    "mcmc_num_steps=1000 # @param\n",
    "\n",
    "mcmc_nchain=1 # @param\n",
    "mcmc_burnin=100 # @param\n",
    "bne_mcmc_initialize_from_map=\"True\" # @param [\"False\", \"True\"]\n",
    "\n",
    "bne_mcmc_initialize_from_map = eval(bne_mcmc_initialize_from_map)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "AMIJk1OdKIj7"
   },
   "outputs": [],
   "source": [
    "# BMA parameters.\n",
    "y_noise_std = 0.01  # Note: Changed from 0.1 # @param\n",
    "bma_gp_lengthscale = 1. # @param\n",
    "bma_gp_l2_regularizer = 0.1 # @param\n",
    "\n",
    "bma_n_samples_train = 100 # @param\n",
    "bma_n_samples_eval = 250 # @param\n",
    "bma_n_samples_test = 250 # @param\n",
    "bma_seed = 0 # @param\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "9iyxQiCJKIn7"
   },
   "outputs": [],
   "source": [
    "# BNE parameters.\n",
    "bne_gp_lengthscale = 4 # 5. # @param\n",
    "bne_gp_l2_regularizer = 5 # 15 # @param\n",
    "bne_variance_prior_mean = -2.5 # @param\n",
    "bne_skewness_prior_mean = -2.5 # @param\n",
    "bne_seed = 0 # @param"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "ojX6KEmzKSEu"
   },
   "outputs": [],
   "source": [
    "bma_config=dict(gp_lengthscale=bma_gp_lengthscale,\n",
    "                gp_l2_regularizer=bma_gp_l2_regularizer,\n",
    "                y_noise_std=y_noise_std,\n",
    "                map_step_size=map_step_size,\n",
    "                map_num_steps=map_num_steps,\n",
    "                mcmc_step_size=mcmc_step_size,\n",
    "                mcmc_num_steps=mcmc_num_steps,\n",
    "                mcmc_initialize_from_map=False,\n",
    "                n_samples_eval=bma_n_samples_eval,\n",
    "                n_samples_train=bma_n_samples_train,\n",
    "                n_samples_test=bma_n_samples_test,\n",
    "                seed=bma_seed)\n",
    "\n",
    "bne_config = dict(gp_lengthscale=bne_gp_lengthscale,\n",
    "                  gp_l2_regularizer=bne_gp_l2_regularizer,\n",
    "                  variance_prior_mean=bne_variance_prior_mean,\n",
    "                  skewness_prior_mean=bne_skewness_prior_mean,\n",
    "                  map_step_size=map_step_size,\n",
    "                  map_num_steps=map_num_steps,\n",
    "                  mcmc_step_size=mcmc_step_size,\n",
    "                  mcmc_num_steps=mcmc_num_steps,\n",
    "                  mcmc_nchain=mcmc_nchain,\n",
    "                  mcmc_burnin=mcmc_burnin,\n",
    "                  mcmc_initialize_from_map=bne_mcmc_initialize_from_map,\n",
    "                  seed=bne_seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bayesian Model Averaging\n",
    "\n",
    "A Bayesian ensemble model where ensemble weights $w_k's$ are parameterized by Gaussian process priors:\n",
    "\n",
    "$y \\sim N(\\mu(x), \\sigma^2)$ \n",
    "\n",
    "$\\mu(x) = \\sum_{k=1}^K w_k(x) * m_k(x) \\quad$  where $\\{m_k\\}_{k=1}^K$ are base model predictions.\n",
    "\n",
    "$w(x) = softmax(f(x)) \\qquad\\;\\;\\;$ where $w=[w_1, \\dots, w_K]$ and $f=[f_1, \\dots, f_K]$\n",
    "\n",
    "$f \\stackrel{i.i.d.}{\\sim} GaussianProcess(0, k)$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model configs.\n",
    "y_noise_std = 0.1  # @param\n",
    "lengthscale=1.  # @param\n",
    "l2_regularizer=0.1  # @param\n",
    "\n",
    "# MCMC configs.\n",
    "map_step_size=0.1 # @param\n",
    "map_num_steps=10_000 # @param\n",
    "\n",
    "mcmc_step_size=0.1 # @param\n",
    "mcmc_num_steps=10_000 # @param\n",
    "\n",
    "# Posterior configs.\n",
    "bma_n_samples_train = 100 # @param\n",
    "bma_n_samples_test = 200 # @param\n",
    "bma_n_samples_eval = 1000  # @param\n",
    "\n",
    "bma_seed = 0  # @param\n",
    "bne_seed = 0 # @param\n",
    "\n",
    "# Assemble into configs.\n",
    "bma_model_config = DEFAULT_GP_CONFIG.copy()\n",
    "map_config = DEFAULT_MAP_CONFIG.copy()\n",
    "mcmc_config = DEFAULT_MCMC_CONFIG.copy()\n",
    "\n",
    "bma_model_config.update(dict(lengthscale=lengthscale,\n",
    "                             l2_regularizer=l2_regularizer,\n",
    "                             y_noise_std=y_noise_std))\n",
    "\n",
    "map_config.update(dict(learning_rate=map_step_size,\n",
    "                       num_steps=map_num_steps))\n",
    "\n",
    "mcmc_config.update(dict(step_size=mcmc_step_size, \n",
    "                        num_steps=mcmc_num_steps))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/liyanran/opt/anaconda3/envs/BNE/lib/python3.7/site-packages/keras/initializers/initializers_v2.py:121: UserWarning: The initializer OrthogonalRandomFeatures is unseeded and being called multiple times, which will return identical values  each time (even if the initializer is unseeded). Please update your code to provide a seed to the initializer, or avoid using the same initalizer instance more than once.\n",
      "  f\"The initializer {self.__class__.__name__} is unseeded \"\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(('gp_weights', ()), ('y', ('gp_weights',)))"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bma_prior, bma_gp_config = bma_dist(X_train1, \n",
    "                                    base_preds_train, \n",
    "                                    **bma_model_config)\n",
    "\n",
    "bma_model_config.update(bma_gp_config)\n",
    "\n",
    "# Check if the model graph is specified correctly.\n",
    "bma_prior.resolve_graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tfp.distributions.JointDistributionNamedAutoBatched 'JointDistributionNamedAutoBatched' batch_shape=[] event_shape={gp_weights: [128, 4], y: [3108, 1]} dtype={gp_weights: float32, y: float32}>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bma_prior"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'learning_rate': 0.1, 'num_steps': 10000}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'step_size': 0.1, 'num_steps': 10000, 'burnin': 2500, 'nchain': 10, 'seed': 0}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'lengthscale': 1.0,\n",
       " 'l2_regularizer': 0.1,\n",
       " 'hidden_units': 128,\n",
       " 'y_noise_std': 0.1,\n",
       " 'units': 4,\n",
       " 'seed': 0}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(map_config,mcmc_config,bma_model_config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run MCMC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running MAP:\t10199233462272.0...13156747264.0...13094498304.0...13020592128.0...12935364608.0...12855286784.0...12800669696.0...12804332544.0...12796621824.0...13083442176.0...Done.\n",
      "Running MCMC:\tAcceptance Ratio: 0.46269989013671875\n"
     ]
    }
   ],
   "source": [
    "mcmc_nchain = 10\n",
    "bma_gp_w_samples = run_posterior_inference(model_dist=bma_prior, \n",
    "                                           model_config=bma_model_config,\n",
    "                                           Y=Y_train, \n",
    "                                           map_config=map_config,\n",
    "                                           mcmc_config=mcmc_config)\n",
    "\n",
    "\n",
    "bma_joint_samples = make_bma_samples(X_test1, Y_test, base_preds_test, \n",
    "                                     bma_weight_samples=bma_gp_w_samples[0],\n",
    "                                     bma_model_config=bma_model_config, \n",
    "                                     n_samples=bma_n_samples_eval, \n",
    "                                     seed=bne_seed,\n",
    "                                     y_samples_only=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "bma_ensemble_weights = bma_joint_samples['ensemble_weights']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lon</th>\n",
       "      <th>lat</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-86.645649</td>\n",
       "      <td>32.540091</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-87.726272</td>\n",
       "      <td>30.738314</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-85.397327</td>\n",
       "      <td>31.874030</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-87.125260</td>\n",
       "      <td>32.999024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-86.562711</td>\n",
       "      <td>33.990440</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3103</th>\n",
       "      <td>-108.878999</td>\n",
       "      <td>41.656512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3104</th>\n",
       "      <td>-110.570974</td>\n",
       "      <td>43.713556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3105</th>\n",
       "      <td>-110.553036</td>\n",
       "      <td>41.289323</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3106</th>\n",
       "      <td>-107.679282</td>\n",
       "      <td>43.909060</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3107</th>\n",
       "      <td>-104.556904</td>\n",
       "      <td>43.843456</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3108 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             lon        lat\n",
       "0     -86.645649  32.540091\n",
       "1     -87.726272  30.738314\n",
       "2     -85.397327  31.874030\n",
       "3     -87.125260  32.999024\n",
       "4     -86.562711  33.990440\n",
       "...          ...        ...\n",
       "3103 -108.878999  41.656512\n",
       "3104 -110.570974  43.713556\n",
       "3105 -110.553036  41.289323\n",
       "3106 -107.679282  43.909060\n",
       "3107 -104.556904  43.843456\n",
       "\n",
       "[3108 rows x 2 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training2010[[\"lon\", \"lat\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'make_color_norm' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/19/s4zdyd_16mb8h239mgwds83m0000gn/T/ipykernel_50081/1522665525.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m }\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m color_norm_weights = make_color_norm(\n\u001b[0m\u001b[1;32m     11\u001b[0m     \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweights_dict\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     method=\"percentile\")\n",
      "\u001b[0;31mNameError\u001b[0m: name 'make_color_norm' is not defined"
     ]
    }
   ],
   "source": [
    "ensemble_weights_val = tf.reduce_mean(bma_ensemble_weights, axis=0)\n",
    "#coordinate = np.asarray(training2010[[\"lon\", \"lat\"]].values.tolist()).astype(np.float32)\n",
    "weights_dict = {\n",
    "    \"acs\": ensemble_weights_val[:, 0],\n",
    "    \"pep\": ensemble_weights_val[:,1],\n",
    "    \"worldpop\": ensemble_weights_val[:, 2],\n",
    "    \"fb\": ensemble_weights_val[:, 3]\n",
    "}\n",
    "\n",
    "color_norm_weights = make_color_norm(\n",
    "    list(weights_dict.values())[1],   \n",
    "    method=\"percentile\")\n",
    "\n",
    "for base_model_name in models:\n",
    "    posterior_heatmap_2d(weights_dict[base_model_name], coordinate,\n",
    "                         cmap='viridis',\n",
    "                         #norm=color_norm_weights, norm_method=\"percentile\",\n",
    "                         save_addr='')\n",
    "                         #save_addr='./pic/'+base_model_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "! conda install geopandas==0.3.0\n",
    "! conda install pyshp==1.2.10\n",
    "! conda install shapely==1.6.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting plotly\n",
      "  Downloading plotly-5.10.0-py2.py3-none-any.whl (15.2 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m15.2/15.2 MB\u001b[0m \u001b[31m14.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting tenacity>=6.2.0\n",
      "  Downloading tenacity-8.1.0-py3-none-any.whl (23 kB)\n",
      "Installing collected packages: tenacity, plotly\n",
      "Successfully installed plotly-5.10.0 tenacity-8.1.0\n",
      "Requirement already satisfied: shapely in /Users/liyanran/opt/anaconda3/envs/BNE/lib/python3.7/site-packages (1.8.5.post1)\n"
     ]
    }
   ],
   "source": [
    "! conda install plotly\n",
    "! conda install shapely"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "geopandas, pyshp and shapely must be installed for this figure factory.\n\nRun the following commands to install the correct versions of the following modules:\n\n```\n$ pip install geopandas==0.3.0\n$ pip install pyshp==1.2.10\n$ pip install shapely==1.6.3\n```\nIf you are using Windows, follow this post to properly install geopandas and dependencies:http://geoffboeing.com/2014/09/using-geopandas-windows/\n\nIf you are using Anaconda, do not use PIP to install the packages above. Instead use conda to install them:\n\n```\n$ conda install plotly\n$ conda install geopandas\n```",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/19/s4zdyd_16mb8h239mgwds83m0000gn/T/ipykernel_50081/273857096.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mvalues\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfips\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0mfig\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mff\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate_choropleth\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfips\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfips\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalues\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0mfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayout\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtemplate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0mfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/BNE/lib/python3.7/site-packages/plotly/figure_factory/_county_choropleth.py\u001b[0m in \u001b[0;36mcreate_choropleth\u001b[0;34m(fips, values, scope, binning_endpoints, colorscale, order, simplify_county, simplify_state, asp, show_hover, show_state_data, state_outline, county_outline, centroid_marker, round_legend_values, exponent_format, legend_title, **layout_options)\u001b[0m\n\u001b[1;32m    623\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mgp\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mshapefile\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mshapely\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    624\u001b[0m         raise ImportError(\n\u001b[0;32m--> 625\u001b[0;31m             \u001b[0;34m\"geopandas, pyshp and shapely must be installed for this figure \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    626\u001b[0m             \u001b[0;34m\"factory.\\n\\nRun the following commands to install the correct \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    627\u001b[0m             \u001b[0;34m\"versions of the following modules:\\n\\n\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mImportError\u001b[0m: geopandas, pyshp and shapely must be installed for this figure factory.\n\nRun the following commands to install the correct versions of the following modules:\n\n```\n$ pip install geopandas==0.3.0\n$ pip install pyshp==1.2.10\n$ pip install shapely==1.6.3\n```\nIf you are using Windows, follow this post to properly install geopandas and dependencies:http://geoffboeing.com/2014/09/using-geopandas-windows/\n\nIf you are using Anaconda, do not use PIP to install the packages above. Instead use conda to install them:\n\n```\n$ conda install plotly\n$ conda install geopandas\n```"
     ]
    }
   ],
   "source": [
    "import plotly.figure_factory as ff\n",
    "\n",
    "fips = ['06021', '06023', '06027',\n",
    "        '06029', '06033', '06059',\n",
    "        '06047', '06049', '06051',\n",
    "        '06055', '06061']\n",
    "values = range(len(fips))\n",
    "\n",
    "fig = ff.create_choropleth(fips=fips, values=values)\n",
    "fig.layout.template = None\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mpl_toolkits.basemap import Basemap #导入Basemap\n",
    "import matplotlib.pyplot as plt  #导入 matplotlib.pyplot\n",
    "fig=plt.figure(figsize=(16, 8)) #表示figure 的大小为宽、长（单位为英寸）\n",
    "#lat_1：南纬度+4，lat_2=北纬度-4，lon_0=-100，设定经度的中心\n",
    "m= Basemap(llcrnrlon=-130, llcrnrlat=20, urcrnrlon=-65, urcrnrlat=49,projection='lcc',lat_1=24, lat_2=45, lon_0=-100)\n",
    "m.drawcountries(linewidth=1.5) # 开始画上国家\n",
    "m.drawcoastlines()  #把海岸线画上\n",
    "m.drawmapboundary(fill_color = 'blue')# 首先给地球涂上蓝色的一层\n",
    "m.drawstates()        # 绘制州\n",
    "m.drawcounties()      # 绘制县，这里好象没有县的划分。\n",
    "m.fillcontinents(color = 'yellow', lake_color = 'aqua')# 再给大陆涂上黄色,给江河湖泊涂上水蓝的颜色\n",
    "plt.show()\n",
    "fig.savefig('../test/America.jpg',dpi=600) \n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [
    "FyVOAW4EODnT",
    "ebzyBOEoNQ_a",
    "vAgjEq1-dty-"
   ],
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
