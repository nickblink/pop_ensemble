{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import wrapper_functions as wf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "lLMUX4tWGIh6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow version: 2.10.0. Expected: 2.7.0\n",
      "TensorFlow Probability version: 0.18.0. Expected: 0.15.0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'/Users/liyanran/Desktop/Research/Rachel/pop_ensemble/code'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from typing import Any, Callable, Dict, List, Optional, Union, Tuple\n",
    "\n",
    "import os\n",
    "import gc\n",
    "import time\n",
    "import pickle\n",
    "import functools\n",
    "\n",
    "import multiprocessing as mp\n",
    "\n",
    "# from google.colab import files\n",
    "# from google.colab import \n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import edward2 as ed\n",
    "import tensorflow_probability as tfp\n",
    "\n",
    "tfd = tfp.distributions\n",
    "tfb = tfp.bijectors\n",
    "\n",
    "dtype = tf.float32\n",
    "import gpflow as gpf\n",
    "import logging\n",
    "\n",
    "logging.getLogger('tensorflow').setLevel(logging.ERROR)  # suppress pfor warnings\n",
    "# Verify versions.\n",
    "print(f'TensorFlow version: {tf.__version__}. Expected: 2.7.0')\n",
    "print(f'TensorFlow Probability version: {tfp.__version__}. Expected: 0.15.0')\n",
    "tf.test.gpu_device_name()\n",
    "\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read in Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['GEOID', 'NAME', 'acs', 'census', 'pep', 'lon', 'lat', 'worldpop',\n",
       "       'fb'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training2010 = pd.read_csv('../data/merged_fb_census_data_280922.csv')\n",
    "training2010.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X, y = np.asarray(training2010[[\"lon\", \"lat\"]].values.tolist()).astype(np.float32),np.asarray(training2010[\"census\"]).astype(np.float32)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.8, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# standardize\n",
    "X_centr = np.mean(X_train, axis=0)\n",
    "X_scale = np.max(X_train, axis=0) - np.min(X_train, axis=0)\n",
    "\n",
    "X_train = (X_train - X_centr) / X_scale\n",
    "\n",
    "X_centr = np.mean(X_test, axis=0)\n",
    "X_scale = np.max(X_test, axis=0) - np.min(X_test, axis=0)\n",
    "\n",
    "X_test = (X_test - X_centr) / X_scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([nan, nan], dtype=float32)"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.max(X_train, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-91.46352 ,  32.78827 ],\n",
       "       [-98.20165 ,  38.33972 ],\n",
       "       [-96.33975 ,  39.36915 ],\n",
       "       ...,\n",
       "       [-89.94534 ,  30.468626],\n",
       "       [-95.36901 ,  47.580032],\n",
       "       [-95.572235,  39.830627]], dtype=float32)"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "TI0wSe45Jhdy"
   },
   "outputs": [],
   "source": [
    "# @title Simulation: run_pipeline\n",
    "def run_pipeline(seeds, N_train, group_id, data_gen_fn, base_train_steps=200):\n",
    "  # Data Generation\n",
    "  data_dicts = {}\n",
    "  print('Data:', end='', flush=True)\n",
    "  t0 = time.time()\n",
    "  for seed in seeds:\n",
    "    print(f'Run {seed+1}...', end='', flush=True)\n",
    "    data_dicts[seed] = get_data(seed, N_train, y_dist, data_gen_fn, \n",
    "                                num_train_steps=base_train_steps)\n",
    "  print(f'Time: {(time.time()-t0)/60.:.4f} min.')\n",
    "\n",
    "  # BMA-mean.\n",
    "  print('BMA-mean:', flush=True)\n",
    "  t0 = time.time()\n",
    "  for seed in seeds:\n",
    "    print(f'Run {seed+1}: ', end='', flush=True)\n",
    "    data_dicts[seed] = get_bma_result(data_dicts[seed], bma_config=bma_config) \n",
    "  print(f'Time: {(time.time()-t0)/60.:.4f} min.', flush=True)\n",
    "  tf.keras.backend.clear_session()\n",
    "  gc.collect()\n",
    "\n",
    "  # BMA.\n",
    "  print('BMA:', flush=True)\n",
    "  # Inhere BMA MCMC configs.\n",
    "  bma_var_config = bne_config.copy()\n",
    "  bma_var_config['mcmc_initialize_from_map'] = bma_config['mcmc_initialize_from_map']\n",
    "  t0 = time.time()\n",
    "  for seed in seeds:\n",
    "    print(f'Run {seed+1}: ', end='', flush=True)\n",
    "    data_dicts[seed] = get_bne_result(data_dicts[seed], moment_mode='none', \n",
    "                                      bne_config=bma_var_config) \n",
    "  print(f'Time: {(time.time()-t0)/60.:.4f} min.', flush=True)\n",
    "  tf.keras.backend.clear_session()\n",
    "  gc.collect()\n",
    "\n",
    "  # BAE.\n",
    "  print('BAE:', flush=True)\n",
    "  t0 = time.time()\n",
    "  for seed in seeds:\n",
    "    print(f'Run {seed+1}: ', end='', flush=True)\n",
    "    data_dicts[seed] = get_bne_result(data_dicts[seed], moment_mode='mean', \n",
    "                                      bne_config=bne_config) \n",
    "  print(f'Time: {(time.time()-t0)/60.:.4f} min.', flush=True)\n",
    "  tf.keras.backend.clear_session()\n",
    "  gc.collect()\n",
    "\n",
    "  # BNE-Variance.\n",
    "  print('BNE-Variance:', flush=True)\n",
    "  t0 = time.time()\n",
    "  for seed in seeds:\n",
    "    print(f'Run {seed+1}: ', end='', flush=True)\n",
    "    data_dicts[seed] = get_bne_result(data_dicts[seed], moment_mode='variance', \n",
    "                                      bne_config=bne_config) \n",
    "  print(f'Time: {(time.time()-t0)/60.:.4f} min.', flush=True)\n",
    "  tf.keras.backend.clear_session()\n",
    "  gc.collect()\n",
    "\n",
    "  # BNE-Skewness.\n",
    "  print('BNE-Skewness:', flush=True)\n",
    "  t0 = time.time()\n",
    "  for seed in seeds:\n",
    "    print(f'Run {seed+1}: ', end='', flush=True)\n",
    "    data_dicts[seed] = get_bne_result(data_dicts[seed], moment_mode='skewness', \n",
    "                                      bne_config=bne_config) \n",
    "  print(f'Time: {(time.time()-t0)/60.:.4f} min.', flush=True)\n",
    "  tf.keras.backend.clear_session()\n",
    "  gc.collect()\n",
    "\n",
    "  return data_dicts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "U-Nmbq-0wgYy"
   },
   "source": [
    "# Default Configs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "zCuDvZJ71_Dz"
   },
   "outputs": [],
   "source": [
    "# GP configs.\n",
    "y_noise_std = 0.1  # @param\n",
    "hidden_units = 128  # @param\n",
    "lengthscale=1.  # @param\n",
    "l2_regularizer=0.1  # @param\n",
    "\n",
    "DEFAULT_GP_CONFIG = dict(lengthscale=lengthscale,\n",
    "                         l2_regularizer=l2_regularizer, \n",
    "                         hidden_units=hidden_units, \n",
    "                         y_noise_std=y_noise_std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "fY1Z6ccs2XUP"
   },
   "outputs": [],
   "source": [
    "# BNE model configs.\n",
    "estimate_mean = \"True\" # @param [\"True\", \"False\"]\n",
    "estimate_variance = \"False\" # @param [\"True\", \"False\"]\n",
    "estimate_skewness = \"False\" # @param [\"True\", \"False\"]\n",
    "variance_prior_mean=0. # @param\n",
    "skewness_prior_mean=0. # @param\n",
    "\n",
    "estimate_mean = eval(estimate_mean)\n",
    "estimate_variance = eval(estimate_variance)\n",
    "estimate_skewness = eval(estimate_skewness)\n",
    "\n",
    "DEFAULT_BNE_CONFIG = dict(estimate_mean=estimate_mean,\n",
    "                          estimate_variance=estimate_variance,\n",
    "                          estimate_skewness=estimate_skewness,\n",
    "                          variance_prior_mean=variance_prior_mean,\n",
    "                          skewness_prior_mean=skewness_prior_mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "_g1YSaRdO7-n"
   },
   "outputs": [],
   "source": [
    "N_train_grid = (25, 50, 100, 250, 500, 750, 1000)   # @param\n",
    "N_base = 250 # @param  \n",
    "N_test = 1000  # @param\n",
    "y_dist_name = \"lognormal\" # @param [\"lognormal\", \"normal\", \"cauchy\"]\n",
    "\n",
    "num_runs =   50# @param\n",
    "num_run_groups = num_runs // 5   # @param\n",
    "\n",
    "if num_run_groups > 0:\n",
    "  seed_groups = [range(num_runs)[i:i+num_runs//num_run_groups] for \n",
    "                 i in range(0, num_runs, num_runs//num_run_groups)]\n",
    "else:\n",
    "  seed_groups = [list(range(num_runs))]\n",
    "\n",
    "dist_dict = {'lognormal': np.random.lognormal,\n",
    "             'normal': np.random.normal,\n",
    "             'cauchy': lambda m, s: np.random.standard_cauchy(size=(m.shape[0], 1)) * s + m}\n",
    "y_dist = dist_dict[y_dist_name]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZHthi3uPKLkr"
   },
   "source": [
    "### Model Configs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "KDl4Di8lKIgm"
   },
   "outputs": [],
   "source": [
    "# Optimization configs. \n",
    "# Consider reduce below parameters / set to `False` if MCMC is taking too long:\n",
    "# mcmc_num_steps, mcmc_burnin, mcmc_nchain, mcmc_initialize_from_map.\n",
    "map_step_size=5e-4   # @param\n",
    "map_num_steps=10_000  # @param\n",
    "\n",
    "mcmc_step_size=1e-4 # @param\n",
    "mcmc_num_steps=1000 # @param\n",
    "\n",
    "mcmc_nchain=1 # @param\n",
    "mcmc_burnin=100 # @param\n",
    "bne_mcmc_initialize_from_map=\"True\" # @param [\"False\", \"True\"]\n",
    "\n",
    "bne_mcmc_initialize_from_map = eval(bne_mcmc_initialize_from_map)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "AMIJk1OdKIj7"
   },
   "outputs": [],
   "source": [
    "# BMA parameters.\n",
    "y_noise_std = 0.01  # Note: Changed from 0.1 # @param\n",
    "bma_gp_lengthscale = 1. # @param\n",
    "bma_gp_l2_regularizer = 0.1 # @param\n",
    "\n",
    "bma_n_samples_train = 100 # @param\n",
    "bma_n_samples_eval = 250 # @param\n",
    "bma_n_samples_test = 250 # @param\n",
    "bma_seed = 0 # @param\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "9iyxQiCJKIn7"
   },
   "outputs": [],
   "source": [
    "# BNE parameters.\n",
    "bne_gp_lengthscale = 4 # 5. # @param\n",
    "bne_gp_l2_regularizer = 5 # 15 # @param\n",
    "bne_variance_prior_mean = -2.5 # @param\n",
    "bne_skewness_prior_mean = -2.5 # @param\n",
    "bne_seed = 0 # @param"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "ojX6KEmzKSEu"
   },
   "outputs": [],
   "source": [
    "bma_config=dict(gp_lengthscale=bma_gp_lengthscale,\n",
    "                gp_l2_regularizer=bma_gp_l2_regularizer,\n",
    "                y_noise_std=y_noise_std,\n",
    "                map_step_size=map_step_size,\n",
    "                map_num_steps=map_num_steps,\n",
    "                mcmc_step_size=mcmc_step_size,\n",
    "                mcmc_num_steps=mcmc_num_steps,\n",
    "                mcmc_initialize_from_map=False,\n",
    "                n_samples_eval=bma_n_samples_eval,\n",
    "                n_samples_train=bma_n_samples_train,\n",
    "                n_samples_test=bma_n_samples_test,\n",
    "                seed=bma_seed)\n",
    "\n",
    "bne_config = dict(gp_lengthscale=bne_gp_lengthscale,\n",
    "                  gp_l2_regularizer=bne_gp_l2_regularizer,\n",
    "                  variance_prior_mean=bne_variance_prior_mean,\n",
    "                  skewness_prior_mean=bne_skewness_prior_mean,\n",
    "                  map_step_size=map_step_size,\n",
    "                  map_num_steps=map_num_steps,\n",
    "                  mcmc_step_size=mcmc_step_size,\n",
    "                  mcmc_num_steps=mcmc_num_steps,\n",
    "                  mcmc_nchain=mcmc_nchain,\n",
    "                  mcmc_burnin=mcmc_burnin,\n",
    "                  mcmc_initialize_from_map=bne_mcmc_initialize_from_map,\n",
    "                  seed=bne_seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run single run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'training_eastMA' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/19/s4zdyd_16mb8h239mgwds83m0000gn/T/ipykernel_85464/737524322.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mX_train1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraining_eastMA\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"lon\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"lat\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;31m# standardize\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mX_centr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mX_scale\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'training_eastMA' is not defined"
     ]
    }
   ],
   "source": [
    "X_train1 = np.asarray(training_eastMA[[\"lon\", \"lat\"]].values.tolist()).astype(np.float32)\n",
    "# standardize\n",
    "X_centr = np.mean(X_train1, axis=0)\n",
    "X_scale = np.max(X_train1, axis=0) - np.min(X_train1, axis=0)\n",
    "\n",
    "X_train1 = (X_train1 - X_centr) / X_scale\n",
    "\n",
    "X_test1 = np.asarray(base_model_predictions_eastMA[[\"lon\", \"lat\"]].values.tolist()).astype(np.float32)\n",
    "# standardize\n",
    "X_centr = np.mean(X_test1, axis=0)\n",
    "X_scale = np.max(X_test1, axis=0) - np.min(X_test1, axis=0)\n",
    "\n",
    "X_test1 = (X_test1 - X_centr) / X_scale\n",
    "\n",
    "Y_train = np.expand_dims(training_eastMA[\"aqs\"], 1)\n",
    "Y_test = np.expand_dims(base_model_predictions_eastMA[\"pred_av\"], 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = ['acs', 'pep', 'worldpop','fb']\n",
    "preds_train = tf.stack([training2010[m] for m in models], axis=-1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# base_preds_train, base_preds_test, kernel_names = run_base_models(\n",
    "#       X_train1, X_train1, X_test1, Y_train, Y_train, Y_test, num_train_steps=100, debug_mode=False)\n",
    "\n",
    "d0 = dict(X_base=X_train1,\n",
    "                   X_train=X_train1,\n",
    "                   X_test=X_test1,\n",
    "                   Y_base=Y_train, \n",
    "                   Y_train=Y_train, \n",
    "                   Y_test=Y_test, \n",
    "                   mean_test=Y_test, \n",
    "                   base_preds_train=base_preds_train, \n",
    "                   base_preds_test=base_preds_test, \n",
    "                   base_model_names=kernel_names)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function wrapper_functions.get_bma_result(data_dict, bma_config)>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wf.get_bma_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 1\n",
    "\n",
    "def run_single2D():\n",
    "    # Data Generation\n",
    "    #data_dicts = {}\n",
    "    data_dicts = d0\n",
    "    # dict_keys(['X_base', 'X_train', 'X_test', 'Y_base', 'Y_train', 'Y_test', 'mean_test', 'base_preds_train', 'base_preds_test', 'base_model_names'])\n",
    "\n",
    "    # BMA-mean.\n",
    "    data_dicts = get_bma_result(d0, bma_config=bma_config) \n",
    "    \n",
    "    # BMA.\n",
    "    # Inhere BMA MCMC configs.\n",
    "    bma_var_config = bne_config.copy()\n",
    "    bma_var_config['mcmc_initialize_from_map'] = bma_config['mcmc_initialize_from_map']\n",
    "    data_dicts = get_bne_result(data_dicts, moment_mode='none', \n",
    "                                      bne_config=bma_var_config) \n",
    "\n",
    "    # BAE.\n",
    "    data_dicts = get_bne_result(data_dicts, moment_mode='mean', \n",
    "                                      bne_config=bne_config) s\n",
    "\n",
    "    # BNE-Variance.\n",
    "    data_dicts = get_bne_result(data_dicts, moment_mode='variance', \n",
    "                                      bne_config=bne_config) \n",
    "\n",
    "\n",
    "    # BNE-Skewness.\n",
    "    data_dicts = get_bne_result(data_dicts, moment_mode='skewness', \n",
    "                                      bne_config=bne_config) \n",
    "\n",
    "    return data_dicts\n",
    "\n",
    "plt_dict1 = run_single2D()    \n",
    " \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eastMA_pred = np.mean(plt_dict1[\"bne_var_samples\"], axis=0)\n",
    "plt.scatter(plt_dict1[\"X_test\"][:,0],plt_dict1[\"X_test\"][:,1], c=eastMA_pred, alpha=1)\n",
    "plt.colorbar()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(plt_dict1.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Wrapper: Plot Utility Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def posterior_heatmap_2d(plot_data, X,\n",
    "                         X_monitor=None,\n",
    "                         cmap='inferno_r',\n",
    "                         norm=None, norm_method=\"percentile\",\n",
    "                         save_addr=''):\n",
    "    \"\"\"Plots colored 2d heatmap using scatterplot.\n",
    "\n",
    "    Args:\n",
    "        plot_data: (np.ndarray) plot data whose color to visualize over\n",
    "            2D surface, shape (N, ).\n",
    "        X: (np.ndarray) locations of the plot data, shape (N, 2).\n",
    "        X_monitor: (np.ndarray or None) Locations to plot data points to.\n",
    "        cmap: (str) Name of color map.\n",
    "        norm: (BoundaryNorm or None) Norm values to adjust color map.\n",
    "            If None then a new norm will be created according to norm_method.\n",
    "        norm_method: (str) The name of method to compute norm values.\n",
    "            See util.visual.make_color_norm for detail.\n",
    "        save_addr: (str) Address to save image to.\n",
    "\n",
    "    Returns:\n",
    "        (matplotlib.colors.BoundaryNorm) A color norm object for color map\n",
    "            to be passed to a matplotlib.pyplot function.\n",
    "    \"\"\"\n",
    "#     if save_addr:\n",
    "#         pathlib.Path(save_addr).parent.mkdir(parents=True, exist_ok=True)\n",
    "#         plt.ioff()\n",
    "\n",
    "#     if not norm:\n",
    "#         norm = make_color_norm(plot_data, method=norm_method)\n",
    "\n",
    "    # 2d color plot using scatter\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    plt.scatter(x=X[:, 0], y=X[:, 1],\n",
    "                s=3,\n",
    "                c=plot_data, cmap=cmap, norm=norm)\n",
    "    cbar = plt.colorbar()\n",
    "\n",
    "    #     plot monitors\n",
    "    if isinstance(X_monitor, np.ndarray):\n",
    "        plt.scatter(x=X_monitor[:, 0], y=X_monitor[:, 1],\n",
    "                    s=10, c='black')\n",
    "\n",
    "    # adjust plot window\n",
    "    plt.xlim((np.min(X[:, 0]), np.max(X[:, 0])))\n",
    "    plt.ylim((np.min(X[:, 1]), np.max(X[:, 1])))\n",
    "\n",
    "    if save_addr:\n",
    "        plt.savefig(save_addr, bbox_inches='tight')\n",
    "        plt.close()\n",
    "        plt.ion()\n",
    "    else:\n",
    "        plt.show()\n",
    "\n",
    "    return norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "posterior_heatmap_2d(eastMA_pred, plt_dict1[\"X_test\"],\n",
    "                         X_train1,\n",
    "                         cmap='RdYlGn_r',\n",
    "                         norm=None, norm_method=\"percentile\",\n",
    "                         save_addr='')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eastMA_pred_var = np.var(plt_dict1[\"bne_var_samples\"], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "posterior_heatmap_2d(eastMA_pred_var, plt_dict1[\"X_test\"],\n",
    "                         X_train1,\n",
    "                         cmap='inferno_r',\n",
    "                         norm=None, norm_method=\"percentile\",\n",
    "                         save_addr='')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QWSzplhQKdqt"
   },
   "source": [
    "### Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2LLseEkxKIqA"
   },
   "outputs": [],
   "source": [
    "# Compute metrics for all N_train and models. \n",
    "metric_rows = []\n",
    "\n",
    "for N_train in N_train_grid:\n",
    "  data_dicts = {}\n",
    "  for group_id in range(len(seed_groups)):\n",
    "    data_dict_group = load_from_drive(\n",
    "        f'result_{N_train}_{group_id}', file_path=FULL_DATA_PATH)\n",
    "    data_dicts.update(data_dict_group)\n",
    "\n",
    "  for model_name in ('bma', 'bae', 'bne_var', 'bne_skew'):\n",
    "    metrics = [compute_metrics(data, model_name, num_sample=50) \n",
    "               for data in data_dicts.values()]\n",
    "    metrics = np.stack(metrics)\n",
    "    metric_means = np.mean(metrics, axis=0)\n",
    "    metric_stds = np.std(metrics, axis=0)\n",
    "\n",
    "    metric_row = dict(n=N_train, \n",
    "                      model_name=model_name, \n",
    "                      # Metric means.\n",
    "                      mse_ind=metric_means[0], \n",
    "                      nll_ind=metric_means[1], \n",
    "                      clb_ind=metric_means[2], \n",
    "                      shp_ind=metric_means[3], \n",
    "                      ece_ind=metric_means[4], \n",
    "                      cov_prob_95_ind=metric_means[5],\n",
    "                      mse_all=metric_means[9], \n",
    "                      nll_all=metric_means[10], \n",
    "                      clb_all=metric_means[11], \n",
    "                      shp_all=metric_means[12], \n",
    "                      ece_all=metric_means[13], \n",
    "                      cov_prob_95_all=metric_means[14],\n",
    "                      # Metric STDs.\n",
    "                      mse_ind_std=metric_stds[0], \n",
    "                      nll_ind_std=metric_stds[1], \n",
    "                      clb_ind_std=metric_stds[2], \n",
    "                      shp_ind_std=metric_stds[3], \n",
    "                      ece_ind_std=metric_stds[4], \n",
    "                      cov_prob_95_ind_std=metric_stds[5],\n",
    "                      mse_all_std=metric_stds[9], \n",
    "                      nll_all_std=metric_stds[10], \n",
    "                      clb_all_std=metric_stds[11], \n",
    "                      shp_all_std=metric_stds[12], \n",
    "                      ece_all_std=metric_stds[13], \n",
    "                      cov_prob_95_all_std=metric_stds[14],\n",
    "                      )\n",
    "    \n",
    "    metric_rows.append(metric_row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "oFdbfztkKgTW",
    "outputId": "219a2280-7db6-49b1-ecc0-bb1fdecfa785"
   },
   "outputs": [],
   "source": [
    "metric_pd = pd.DataFrame(metric_rows)\n",
    "metric_pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# base_preds_train, base_preds_test, kernel_names = run_base_models(\n",
    "#       plt_dict0['X_base'], plt_dict0['X_train'], plt_dict0['X_test'], plt_dict0['Y_base'], plt_dict0['Y_train'], \n",
    "#       plt_dict0['Y_test'], num_train_steps=100)\n",
    "# d0 = dict(X_base=plt_dict0['X_base'],\n",
    "#                    X_train=plt_dict0['X_train'],\n",
    "#                    X_test=plt_dict0['X_test'],\n",
    "#                    Y_base=plt_dict0['Y_base'], \n",
    "#                    Y_train=plt_dict0['Y_train'], \n",
    "#                    Y_test=plt_dict0['Y_test'], \n",
    "#                    mean_test=plt_dict0['mean_test'], \n",
    "#                    base_preds_train=base_preds_train, \n",
    "#                    base_preds_test=base_preds_test, \n",
    "#                    base_model_names=kernel_names)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 267
    },
    "id": "VaG6bpWaLMfl",
    "outputId": "1cc81a4a-bf96-4a4e-c7c1-09423c9246c6"
   },
   "outputs": [],
   "source": [
    "metric_pd_2d = metric_pd.copy()\n",
    "metric_pd_wide = metric_pd_2d[['model_name', 'n', \n",
    "                               # 'mse_ind',\t\n",
    "                               'nll_ind', 'nll_all',\n",
    "                               'clb_ind', 'clb_all',\n",
    "                               'shp_ind', 'shp_all',\n",
    "                               'ece_ind', 'ece_all',\n",
    "                               'cov_prob_95_ind', 'cov_prob_95_all']]\n",
    "metric_pd_wide.pivot(index='model_name',columns='n').round(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tTENngJkJryh"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "cellView": "form",
    "colab": {
     "background_save": true
    },
    "id": "N-18GdxrKzbI"
   },
   "outputs": [],
   "source": [
    "# @title Simulation: compute_metrics\n",
    "def compute_metrics(data_dict, model_name, q_true=None, ind_ids=None, num_sample=None):\n",
    "  if q_true is None:\n",
    "    q_true = np.array(\n",
    "        [0.025, 0.05, 0.075, 0.1, 0.15, 0.2, 0.25,\n",
    "         0.75, 0.8, 0.85, 0.9, 0.925, 0.95, 0.975])\n",
    "\n",
    "  if ind_ids is None:\n",
    "    # Find IDs of in-domain test data via range comparison \n",
    "    # between X_train and X_test.\n",
    "    X_train_min = np.min(data_dict['X_train'], axis=0)\n",
    "    X_train_max = np.max(data_dict['X_train'], axis=0)\n",
    "\n",
    "    test_ids_greater_than_min = np.all(\n",
    "        data_dict['X_test'] > X_train_min, axis=-1)\n",
    "    test_ids_less_than_max = np.all(\n",
    "        data_dict['X_test'] < X_train_max, axis=-1)\n",
    "\n",
    "    ind_ids = np.where(\n",
    "        np.logical_and(test_ids_greater_than_min, test_ids_less_than_max))[0]\n",
    "\n",
    "  samples = data_dict[f'{model_name}_samples']\n",
    "  means_true = data_dict['mean_test']\n",
    "  y_test = data_dict['Y_test']\n",
    "\n",
    "  if num_sample is not None:\n",
    "    samples = samples[:num_sample]\n",
    "\n",
    "  means_pred = np.mean(samples, axis=0)\n",
    "  stds_pred = np.std(samples, axis=0)\n",
    "  quantile_pred = np.quantile(samples, q=q_true, axis=0)\n",
    "\n",
    "  # Compute in-domain metrics.\n",
    "  nll_ind = np.mean(\n",
    "      ((means_pred[ind_ids] - means_true[ind_ids])/stds_pred[ind_ids])**2 + \n",
    "      np.log(stds_pred[ind_ids]))\n",
    "  clb_ind = np.mean(\n",
    "      ((means_pred[ind_ids] - means_true[ind_ids])/stds_pred[ind_ids])**2)\n",
    "  shp_ind = np.mean(np.log(stds_pred[ind_ids]))\n",
    "  mse_ind = np.mean(\n",
    "      (means_pred[ind_ids] - means_true[ind_ids])**2) / np.var(means_true[ind_ids])\n",
    "\n",
    "  q_pred_ind = np.mean(y_test[ind_ids] < quantile_pred[:, ind_ids], axis=(1, 2))\n",
    "  ece_ind = np.mean((q_pred_ind - q_true)**2)\n",
    "  cov_prob_95_ind = q_pred_ind[-1] - q_pred_ind[0]\n",
    "  cov_prob_90_ind = q_pred_ind[-2] - q_pred_ind[1]\n",
    "  cov_prob_85_ind = q_pred_ind[-3] - q_pred_ind[2]\n",
    "  cov_prob_80_ind = q_pred_ind[-4] - q_pred_ind[3]\n",
    "\n",
    "  # Compute all-domain (ind + ood) metrics.\n",
    "  nll_all = np.mean(((means_pred - means_true)/stds_pred)**2 + np.log(stds_pred))\n",
    "  clb_all = np.mean(((means_pred - means_true)/stds_pred)**2)\n",
    "  shp_all = np.mean(np.log(stds_pred))\n",
    "  mse_all = np.mean((means_pred - means_true)**2) / np.var(means_true)\n",
    "\n",
    "  q_pred_all = np.mean(y_test < quantile_pred, axis=(1, 2))\n",
    "  ece_all = np.mean((q_pred_all - q_true)**2)\n",
    "  cov_prob_95_all = q_pred_all[-1] - q_pred_all[0]\n",
    "  cov_prob_90_all = q_pred_all[-2] - q_pred_all[1]\n",
    "  cov_prob_85_all = q_pred_all[-3] - q_pred_all[2]\n",
    "  cov_prob_80_all = q_pred_all[-4] - q_pred_all[3]\n",
    "\n",
    "  return (mse_ind, nll_ind, clb_ind, shp_ind, ece_ind, cov_prob_95_ind, cov_prob_90_ind, cov_prob_85_ind, cov_prob_80_ind,\n",
    "          mse_all, nll_all, clb_all, shp_all, ece_all, cov_prob_95_all, cov_prob_90_all, cov_prob_85_all, cov_prob_80_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [
    "FyVOAW4EODnT",
    "ebzyBOEoNQ_a",
    "vAgjEq1-dty-"
   ],
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
