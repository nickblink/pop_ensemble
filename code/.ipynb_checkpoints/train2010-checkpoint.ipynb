{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "from wrapper_functions import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "lLMUX4tWGIh6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow version: 2.10.0. Expected: 2.7.0\n",
      "TensorFlow Probability version: 0.18.0. Expected: 0.15.0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'/Users/liyanran/Desktop/Research/Rachel/pop_ensemble/code'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from typing import Any, Callable, Dict, List, Optional, Union, Tuple\n",
    "\n",
    "import os\n",
    "import gc\n",
    "import time\n",
    "import pickle\n",
    "import functools\n",
    "\n",
    "import multiprocessing as mp\n",
    "\n",
    "# from google.colab import files\n",
    "# from google.colab import \n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import edward2 as ed\n",
    "import tensorflow_probability as tfp\n",
    "\n",
    "tfd = tfp.distributions\n",
    "tfb = tfp.bijectors\n",
    "\n",
    "dtype = tf.float32\n",
    "import gpflow as gpf\n",
    "import logging\n",
    "\n",
    "logging.getLogger('tensorflow').setLevel(logging.ERROR)  # suppress pfor warnings\n",
    "# Verify versions.\n",
    "print(f'TensorFlow version: {tf.__version__}. Expected: 2.7.0')\n",
    "print(f'TensorFlow Probability version: {tfp.__version__}. Expected: 0.15.0')\n",
    "tf.test.gpu_device_name()\n",
    "\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def posterior_heatmap_2d(plot_data, X,\n",
    "                         cmap='inferno_r',\n",
    "                         #norm=None, norm_method=\"percentile\",\n",
    "                         save_addr=''):\n",
    "    \"\"\"Plots colored 2d heatmap using scatterplot.\n",
    "\n",
    "    Args:\n",
    "        plot_data: (np.ndarray) plot data whose color to visualize over\n",
    "            2D surface, shape (N, ).\n",
    "        X: (np.ndarray) locations of the plot data, shape (N, 2).\n",
    "        X_monitor: (np.ndarray or None) Locations to plot data points to.\n",
    "        cmap: (str) Name of color map.\n",
    "        norm: (BoundaryNorm or None) Norm values to adjust color map.\n",
    "            If None then a new norm will be created according to norm_method.\n",
    "        norm_method: (str) The name of method to compute norm values.\n",
    "            See util.visual.make_color_norm for detail.\n",
    "        save_addr: (str) Address to save image to.\n",
    "\n",
    "    Returns:\n",
    "        (matplotlib.colors.BoundaryNorm) A color norm object for color map\n",
    "            to be passed to a matplotlib.pyplot function.\n",
    "    \"\"\"\n",
    "#     if save_addr:\n",
    "#         pathlib.Path(save_addr).parent.mkdir(parents=True, exist_ok=True)\n",
    "#         plt.ioff()\n",
    "\n",
    "#     if not norm:\n",
    "#         norm = make_color_norm(plot_data, method=norm_method)\n",
    "\n",
    "    # 2d color plot using scatter\n",
    "    plt.figure(figsize=(12, 8))\n",
    "    plt.scatter(x=X[:, 0], y=X[:, 1],\n",
    "                s=3,\n",
    "                c=plot_data, cmap=cmap)#, norm=norm)\n",
    "    cbar = plt.colorbar()\n",
    "\n",
    "    #     plot monitors \"lon\", \"lat\"\n",
    "#     if isinstance(X_monitor, np.ndarray):\n",
    "#         plt.scatter(x=X_monitor[:, 0], y=X_monitor[:, 1],\n",
    "#                     s=10, c='black')\n",
    "\n",
    "    # adjust plot window\n",
    "#     plt.xlim((np.nanmin(X[:, 0]), np.nanmax(X[:, 0])))\n",
    "#     plt.ylim((np.nanmin(X[:, 1]), np.nanmax(X[:, 1])))\n",
    "\n",
    "    if save_addr:\n",
    "        plt.savefig(save_addr, bbox_inches='tight')\n",
    "        plt.close()\n",
    "        plt.ion()\n",
    "    else:\n",
    "        plt.show()\n",
    "\n",
    "    #return norm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read in Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "training2010 = pd.read_csv('../data/merged_fb_census_data_280922.csv')\n",
    "coordinate = np.asarray(training2010[[\"lon\", \"lat\"]].values.tolist()).astype(np.float32)\n",
    "training2010=training2010.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([3108, 4])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TensorShape([3108, 4])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2010 center and scale:  [-90.83139   37.882298] [124.135445  48.820534]\n"
     ]
    }
   ],
   "source": [
    "models = ['acs', 'pep', 'worldpop','fb']\n",
    "# base_preds_train = tf.stack([training2010[m] for m in models], axis=-1).astype(np.float32)\n",
    "# base_preds_test = tf.stack([training2010[m] for m in models], axis=-1).astype(np.float32)\n",
    "\n",
    "\n",
    "# standardize\n",
    "X_train1 = np.asarray(training2010[[\"lon\", \"lat\"]].values.tolist()).astype(np.float32)\n",
    "X_test1 = np.asarray(training2010[[\"lon\", \"lat\"]].values.tolist()).astype(np.float32)\n",
    "X_valid = np.concatenate((X_train1, X_test1), axis=0)\n",
    "X_centr = np.nanmean(X_valid, axis=0)\n",
    "X_scale = np.nanmax(X_valid, axis=0) - np.nanmin(X_valid, axis=0)\n",
    "\n",
    "X_train1 = (X_train1 - X_centr) / X_scale\n",
    "X_test1 = (X_test1 - X_centr) / X_scale\n",
    "\n",
    "Y_train = np.expand_dims(training2010[\"census\"], 1).astype(np.float32)\n",
    "\n",
    "Y_test = np.expand_dims(training2010[\"census\"], 1).astype(np.float32)\n",
    "\n",
    "base_preds_train = tf.stack([training2010[m].astype(np.float32) for m in models], axis=-1)\n",
    "base_preds_test = tf.stack([training2010[m].astype(np.float32) for m in models], axis=-1)\n",
    "display(base_preds_train.shape, base_preds_test.shape)\n",
    "\n",
    "\n",
    "print(\"2010 center and scale: \", X_centr, X_scale)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.03371918, -0.10942537],\n",
       "       [ 0.02501395, -0.14633153],\n",
       "       [ 0.04377531, -0.12306847],\n",
       "       ...,\n",
       "       [-0.15887196,  0.06978671],\n",
       "       [-0.13572185,  0.12344731],\n",
       "       [-0.11056888,  0.12210351]], dtype=float32)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X, y = np.asarray(training2010[[\"lon\", \"lat\"]].values.tolist()).astype(np.float32),np.asarray(training2010[\"census\"]).astype(np.float32)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.8, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "U-Nmbq-0wgYy"
   },
   "source": [
    "# Default Configs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "zCuDvZJ71_Dz"
   },
   "outputs": [],
   "source": [
    "# GP configs.\n",
    "y_noise_std = 0.1  # @param\n",
    "hidden_units = 128  # @param\n",
    "lengthscale=1.  # @param\n",
    "l2_regularizer=0.1  # @param\n",
    "\n",
    "DEFAULT_GP_CONFIG = dict(lengthscale=lengthscale,\n",
    "                         l2_regularizer=l2_regularizer, \n",
    "                         hidden_units=hidden_units, \n",
    "                         y_noise_std=y_noise_std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "fY1Z6ccs2XUP"
   },
   "outputs": [],
   "source": [
    "# BNE model configs.\n",
    "estimate_mean = \"True\" # @param [\"True\", \"False\"]\n",
    "estimate_variance = \"False\" # @param [\"True\", \"False\"]\n",
    "estimate_skewness = \"False\" # @param [\"True\", \"False\"]\n",
    "variance_prior_mean=0. # @param\n",
    "skewness_prior_mean=0. # @param\n",
    "\n",
    "estimate_mean = eval(estimate_mean)\n",
    "estimate_variance = eval(estimate_variance)\n",
    "estimate_skewness = eval(estimate_skewness)\n",
    "\n",
    "DEFAULT_BNE_CONFIG = dict(estimate_mean=estimate_mean,\n",
    "                          estimate_variance=estimate_variance,\n",
    "                          estimate_skewness=estimate_skewness,\n",
    "                          variance_prior_mean=variance_prior_mean,\n",
    "                          skewness_prior_mean=skewness_prior_mean)\n",
    "\n",
    "# MAP configs.\n",
    "map_step_size=0.1 # @param\n",
    "map_num_steps=10_000 # @param\n",
    "\n",
    "DEFAULT_MAP_CONFIG = dict(learning_rate=map_step_size,\n",
    "                          num_steps=map_num_steps)\n",
    "\n",
    "# MCMC configs.\n",
    "mcmc_step_size=0.1 # @param\n",
    "mcmc_sample_size=500 # @param\n",
    "mcmc_num_steps=10_000 # @param\n",
    "mcmc_burnin=2_500 # @param\n",
    "mcmc_nchain=10 # @param\n",
    "mcmc_seed=0 # @param\n",
    "\n",
    "DEFAULT_MCMC_CONFIG = dict(step_size=mcmc_step_size, \n",
    "                           num_steps=mcmc_sample_size, \n",
    "                           burnin=mcmc_burnin, \n",
    "                           nchain=mcmc_nchain, \n",
    "                           seed=mcmc_seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model configs.\n",
    "y_noise_std = 0.1  # @param\n",
    "lengthscale=1.  # @param\n",
    "l2_regularizer=0.1  # @param\n",
    "\n",
    "# MCMC configs.\n",
    "map_step_size=0.1 # @param\n",
    "map_num_steps=10_000 # @param\n",
    "\n",
    "mcmc_step_size=0.1 # @param\n",
    "mcmc_num_steps=10_000 # @param\n",
    "\n",
    "# Posterior configs.\n",
    "bma_n_samples_train = 100 # @param\n",
    "bma_n_samples_test = 200 # @param\n",
    "bma_n_samples_eval = 1000  # @param\n",
    "\n",
    "bma_seed = 0  # @param\n",
    "bne_seed = 0 # @param\n",
    "\n",
    "# Assemble into configs.\n",
    "bma_model_config = DEFAULT_GP_CONFIG.copy()\n",
    "map_config = DEFAULT_MAP_CONFIG.copy()\n",
    "mcmc_config = DEFAULT_MCMC_CONFIG.copy()\n",
    "\n",
    "bma_model_config.update(dict(lengthscale=lengthscale,\n",
    "                             l2_regularizer=l2_regularizer,\n",
    "                             y_noise_std=y_noise_std))\n",
    "\n",
    "map_config.update(dict(learning_rate=map_step_size,\n",
    "                       num_steps=map_num_steps))\n",
    "\n",
    "mcmc_config.update(dict(step_size=mcmc_step_size, \n",
    "                        num_steps=mcmc_num_steps))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZHthi3uPKLkr"
   },
   "source": [
    "### Model Configs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "KDl4Di8lKIgm"
   },
   "outputs": [],
   "source": [
    "# Optimization configs. \n",
    "# Consider reduce below parameters / set to `False` if MCMC is taking too long:\n",
    "# mcmc_num_steps, mcmc_burnin, mcmc_nchain, mcmc_initialize_from_map.\n",
    "map_step_size=5e-4   # @param\n",
    "map_num_steps=10_000  # @param\n",
    "\n",
    "mcmc_step_size=1e-4 # @param\n",
    "mcmc_num_steps=1000 # @param\n",
    "\n",
    "mcmc_nchain=1 # @param\n",
    "mcmc_burnin=100 # @param\n",
    "bne_mcmc_initialize_from_map=\"True\" # @param [\"False\", \"True\"]\n",
    "\n",
    "bne_mcmc_initialize_from_map = eval(bne_mcmc_initialize_from_map)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "AMIJk1OdKIj7"
   },
   "outputs": [],
   "source": [
    "# BMA parameters.\n",
    "y_noise_std = 0.01  # Note: Changed from 0.1 # @param\n",
    "bma_gp_lengthscale = 1. # @param\n",
    "bma_gp_l2_regularizer = 0.1 # @param\n",
    "\n",
    "bma_n_samples_train = 100 # @param\n",
    "bma_n_samples_eval = 250 # @param\n",
    "bma_n_samples_test = 250 # @param\n",
    "bma_seed = 0 # @param\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "9iyxQiCJKIn7"
   },
   "outputs": [],
   "source": [
    "# BNE parameters.\n",
    "bne_gp_lengthscale = 4 # 5. # @param\n",
    "bne_gp_l2_regularizer = 5 # 15 # @param\n",
    "bne_variance_prior_mean = -2.5 # @param\n",
    "bne_skewness_prior_mean = -2.5 # @param\n",
    "bne_seed = 0 # @param"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "ojX6KEmzKSEu"
   },
   "outputs": [],
   "source": [
    "bma_config=dict(gp_lengthscale=bma_gp_lengthscale,\n",
    "                gp_l2_regularizer=bma_gp_l2_regularizer,\n",
    "                y_noise_std=y_noise_std,\n",
    "                map_step_size=map_step_size,\n",
    "                map_num_steps=map_num_steps,\n",
    "                mcmc_step_size=mcmc_step_size,\n",
    "                mcmc_num_steps=mcmc_num_steps,\n",
    "                mcmc_initialize_from_map=False,\n",
    "                n_samples_eval=bma_n_samples_eval,\n",
    "                n_samples_train=bma_n_samples_train,\n",
    "                n_samples_test=bma_n_samples_test,\n",
    "                seed=bma_seed)\n",
    "\n",
    "bne_config = dict(gp_lengthscale=bne_gp_lengthscale,\n",
    "                  gp_l2_regularizer=bne_gp_l2_regularizer,\n",
    "                  variance_prior_mean=bne_variance_prior_mean,\n",
    "                  skewness_prior_mean=bne_skewness_prior_mean,\n",
    "                  map_step_size=map_step_size,\n",
    "                  map_num_steps=map_num_steps,\n",
    "                  mcmc_step_size=mcmc_step_size,\n",
    "                  mcmc_num_steps=mcmc_num_steps,\n",
    "                  mcmc_nchain=mcmc_nchain,\n",
    "                  mcmc_burnin=mcmc_burnin,\n",
    "                  mcmc_initialize_from_map=bne_mcmc_initialize_from_map,\n",
    "                  seed=bne_seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bayesian Model Averaging\n",
    "\n",
    "A Bayesian ensemble model where ensemble weights $w_k's$ are parameterized by Gaussian process priors:\n",
    "\n",
    "$y \\sim N(\\mu(x), \\sigma^2)$ \n",
    "\n",
    "$\\mu(x) = \\sum_{k=1}^K w_k(x) * m_k(x) \\quad$  where $\\{m_k\\}_{k=1}^K$ are base model predictions.\n",
    "\n",
    "$w(x) = softmax(f(x)) \\qquad\\;\\;\\;$ where $w=[w_1, \\dots, w_K]$ and $f=[f_1, \\dots, f_K]$\n",
    "\n",
    "$f \\stackrel{i.i.d.}{\\sim} GaussianProcess(0, k)$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model configs.\n",
    "y_noise_std = 0.1  # @param\n",
    "lengthscale=1.  # @param\n",
    "l2_regularizer=0.1  # @param\n",
    "\n",
    "# MCMC configs.\n",
    "map_step_size=0.1 # @param\n",
    "map_num_steps=10_000 # @param\n",
    "\n",
    "mcmc_step_size=0.1 # @param\n",
    "mcmc_num_steps=10_000 # @param\n",
    "\n",
    "# Posterior configs.\n",
    "bma_n_samples_train = 100 # @param\n",
    "bma_n_samples_test = 200 # @param\n",
    "bma_n_samples_eval = 1000  # @param\n",
    "\n",
    "bma_seed = 0  # @param\n",
    "bne_seed = 0 # @param\n",
    "\n",
    "# Assemble into configs.\n",
    "bma_model_config = DEFAULT_GP_CONFIG.copy()\n",
    "map_config = DEFAULT_MAP_CONFIG.copy()\n",
    "mcmc_config = DEFAULT_MCMC_CONFIG.copy()\n",
    "\n",
    "bma_model_config.update(dict(lengthscale=lengthscale,\n",
    "                             l2_regularizer=l2_regularizer,\n",
    "                             y_noise_std=y_noise_std))\n",
    "\n",
    "map_config.update(dict(learning_rate=map_step_size,\n",
    "                       num_steps=map_num_steps))\n",
    "\n",
    "mcmc_config.update(dict(step_size=mcmc_step_size, \n",
    "                        num_steps=mcmc_num_steps))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/liyanran/opt/anaconda3/envs/BNE/lib/python3.7/site-packages/keras/initializers/initializers_v2.py:121: UserWarning: The initializer OrthogonalRandomFeatures is unseeded and being called multiple times, which will return identical values  each time (even if the initializer is unseeded). Please update your code to provide a seed to the initializer, or avoid using the same initalizer instance more than once.\n",
      "  f\"The initializer {self.__class__.__name__} is unseeded \"\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(('gp_weights', ()), ('y', ('gp_weights',)))"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bma_prior, bma_gp_config = bma_dist(X_train1, \n",
    "                                    base_preds_train, \n",
    "                                    **bma_model_config)\n",
    "\n",
    "bma_model_config.update(bma_gp_config)\n",
    "\n",
    "# Check if the model graph is specified correctly.\n",
    "bma_prior.resolve_graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tfp.distributions.JointDistributionNamedAutoBatched 'JointDistributionNamedAutoBatched' batch_shape=[] event_shape={gp_weights: [128, 4], y: [3108, 1]} dtype={gp_weights: float32, y: float32}>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bma_prior"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'learning_rate': 0.1, 'num_steps': 10000}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'step_size': 0.1, 'num_steps': 10000, 'burnin': 2500, 'nchain': 10, 'seed': 0}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'lengthscale': 1.0,\n",
       " 'l2_regularizer': 0.1,\n",
       " 'hidden_units': 128,\n",
       " 'y_noise_std': 0.1,\n",
       " 'units': 4,\n",
       " 'seed': 0}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(map_config,mcmc_config,bma_model_config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run MCMC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running MAP:\t10129749573632.0...13029293056.0...12917168128.0...12850932736.0...12814694400.0...12798589952.0...12791627776.0...13083279360.0...13074496512.0...12848691200.0...Done.\n",
      "Running MCMC:\tAcceptance Ratio: 0.32959994673728943\n"
     ]
    }
   ],
   "source": [
    "mcmc_nchain = 10\n",
    "bma_gp_w_samples = run_posterior_inference(model_dist=bma_prior, \n",
    "                                           model_config=bma_model_config,\n",
    "                                           Y=Y_train, \n",
    "                                           map_config=map_config,\n",
    "                                           mcmc_config=mcmc_config)\n",
    "\n",
    "\n",
    "bma_joint_samples = make_bma_samples(X_test1, Y_test, base_preds_test, \n",
    "                                     bma_weight_samples=bma_gp_w_samples[0],\n",
    "                                     bma_model_config=bma_model_config, \n",
    "                                     n_samples=bma_n_samples_eval, \n",
    "                                     seed=bne_seed,\n",
    "                                     y_samples_only=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "bma_ensemble_weights = bma_joint_samples['ensemble_weights']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lon</th>\n",
       "      <th>lat</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-86.645649</td>\n",
       "      <td>32.540091</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-87.726272</td>\n",
       "      <td>30.738314</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-85.397327</td>\n",
       "      <td>31.874030</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-87.125260</td>\n",
       "      <td>32.999024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-86.562711</td>\n",
       "      <td>33.990440</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3103</th>\n",
       "      <td>-108.878999</td>\n",
       "      <td>41.656512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3104</th>\n",
       "      <td>-110.570974</td>\n",
       "      <td>43.713556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3105</th>\n",
       "      <td>-110.553036</td>\n",
       "      <td>41.289323</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3106</th>\n",
       "      <td>-107.679282</td>\n",
       "      <td>43.909060</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3107</th>\n",
       "      <td>-104.556904</td>\n",
       "      <td>43.843456</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3108 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             lon        lat\n",
       "0     -86.645649  32.540091\n",
       "1     -87.726272  30.738314\n",
       "2     -85.397327  31.874030\n",
       "3     -87.125260  32.999024\n",
       "4     -86.562711  33.990440\n",
       "...          ...        ...\n",
       "3103 -108.878999  41.656512\n",
       "3104 -110.570974  43.713556\n",
       "3105 -110.553036  41.289323\n",
       "3106 -107.679282  43.909060\n",
       "3107 -104.556904  43.843456\n",
       "\n",
       "[3108 rows x 2 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training2010[[\"lon\", \"lat\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'make_color_norm' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/19/s4zdyd_16mb8h239mgwds83m0000gn/T/ipykernel_50081/1522665525.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m }\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m color_norm_weights = make_color_norm(\n\u001b[0m\u001b[1;32m     11\u001b[0m     \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweights_dict\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     method=\"percentile\")\n",
      "\u001b[0;31mNameError\u001b[0m: name 'make_color_norm' is not defined"
     ]
    }
   ],
   "source": [
    "ensemble_weights_val = tf.reduce_mean(bma_ensemble_weights, axis=0)\n",
    "#coordinate = np.asarray(training2010[[\"lon\", \"lat\"]].values.tolist()).astype(np.float32)\n",
    "weights_dict = {\n",
    "    \"acs\": ensemble_weights_val[:, 0],\n",
    "    \"pep\": ensemble_weights_val[:,1],\n",
    "    \"worldpop\": ensemble_weights_val[:, 2],\n",
    "    \"fb\": ensemble_weights_val[:, 3]\n",
    "}\n",
    "\n",
    "color_norm_weights = make_color_norm(\n",
    "    list(weights_dict.values())[1],   \n",
    "    method=\"percentile\")\n",
    "\n",
    "for base_model_name in models:\n",
    "    posterior_heatmap_2d(weights_dict[base_model_name], coordinate,\n",
    "                         cmap='viridis',\n",
    "                         #norm=color_norm_weights, norm_method=\"percentile\",\n",
    "                         save_addr='')\n",
    "                         #save_addr='./pic/'+base_model_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "! conda install geopandas==0.3.0\n",
    "! conda install pyshp==1.2.10\n",
    "! conda install shapely==1.6.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting plotly\n",
      "  Downloading plotly-5.10.0-py2.py3-none-any.whl (15.2 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m15.2/15.2 MB\u001b[0m \u001b[31m14.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting tenacity>=6.2.0\n",
      "  Downloading tenacity-8.1.0-py3-none-any.whl (23 kB)\n",
      "Installing collected packages: tenacity, plotly\n",
      "Successfully installed plotly-5.10.0 tenacity-8.1.0\n",
      "Requirement already satisfied: shapely in /Users/liyanran/opt/anaconda3/envs/BNE/lib/python3.7/site-packages (1.8.5.post1)\n"
     ]
    }
   ],
   "source": [
    "! conda install plotly\n",
    "! conda install shapely"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "geopandas, pyshp and shapely must be installed for this figure factory.\n\nRun the following commands to install the correct versions of the following modules:\n\n```\n$ pip install geopandas==0.3.0\n$ pip install pyshp==1.2.10\n$ pip install shapely==1.6.3\n```\nIf you are using Windows, follow this post to properly install geopandas and dependencies:http://geoffboeing.com/2014/09/using-geopandas-windows/\n\nIf you are using Anaconda, do not use PIP to install the packages above. Instead use conda to install them:\n\n```\n$ conda install plotly\n$ conda install geopandas\n```",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/19/s4zdyd_16mb8h239mgwds83m0000gn/T/ipykernel_50081/273857096.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mvalues\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfips\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0mfig\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mff\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate_choropleth\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfips\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfips\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalues\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0mfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayout\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtemplate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0mfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/BNE/lib/python3.7/site-packages/plotly/figure_factory/_county_choropleth.py\u001b[0m in \u001b[0;36mcreate_choropleth\u001b[0;34m(fips, values, scope, binning_endpoints, colorscale, order, simplify_county, simplify_state, asp, show_hover, show_state_data, state_outline, county_outline, centroid_marker, round_legend_values, exponent_format, legend_title, **layout_options)\u001b[0m\n\u001b[1;32m    623\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mgp\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mshapefile\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mshapely\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    624\u001b[0m         raise ImportError(\n\u001b[0;32m--> 625\u001b[0;31m             \u001b[0;34m\"geopandas, pyshp and shapely must be installed for this figure \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    626\u001b[0m             \u001b[0;34m\"factory.\\n\\nRun the following commands to install the correct \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    627\u001b[0m             \u001b[0;34m\"versions of the following modules:\\n\\n\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mImportError\u001b[0m: geopandas, pyshp and shapely must be installed for this figure factory.\n\nRun the following commands to install the correct versions of the following modules:\n\n```\n$ pip install geopandas==0.3.0\n$ pip install pyshp==1.2.10\n$ pip install shapely==1.6.3\n```\nIf you are using Windows, follow this post to properly install geopandas and dependencies:http://geoffboeing.com/2014/09/using-geopandas-windows/\n\nIf you are using Anaconda, do not use PIP to install the packages above. Instead use conda to install them:\n\n```\n$ conda install plotly\n$ conda install geopandas\n```"
     ]
    }
   ],
   "source": [
    "import plotly.figure_factory as ff\n",
    "\n",
    "fips = ['06021', '06023', '06027',\n",
    "        '06029', '06033', '06059',\n",
    "        '06047', '06049', '06051',\n",
    "        '06055', '06061']\n",
    "values = range(len(fips))\n",
    "\n",
    "fig = ff.create_choropleth(fips=fips, values=values)\n",
    "fig.layout.template = None\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mpl_toolkits.basemap import Basemap #导入Basemap\n",
    "import matplotlib.pyplot as plt  #导入 matplotlib.pyplot\n",
    "fig=plt.figure(figsize=(16, 8)) #表示figure 的大小为宽、长（单位为英寸）\n",
    "#lat_1：南纬度+4，lat_2=北纬度-4，lon_0=-100，设定经度的中心\n",
    "m= Basemap(llcrnrlon=-130, llcrnrlat=20, urcrnrlon=-65, urcrnrlat=49,projection='lcc',lat_1=24, lat_2=45, lon_0=-100)\n",
    "m.drawcountries(linewidth=1.5) # 开始画上国家\n",
    "m.drawcoastlines()  #把海岸线画上\n",
    "m.drawmapboundary(fill_color = 'blue')# 首先给地球涂上蓝色的一层\n",
    "m.drawstates()        # 绘制州\n",
    "m.drawcounties()      # 绘制县，这里好象没有县的划分。\n",
    "m.fillcontinents(color = 'yellow', lake_color = 'aqua')# 再给大陆涂上黄色,给江河湖泊涂上水蓝的颜色\n",
    "plt.show()\n",
    "fig.savefig('../test/America.jpg',dpi=600) \n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [
    "FyVOAW4EODnT",
    "ebzyBOEoNQ_a",
    "vAgjEq1-dty-"
   ],
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
