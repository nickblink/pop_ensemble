{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from wrapper_functions import *\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read in Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "training2010 = pd.read_csv('../data/merged_wp_census_data_NY_081122.csv')\n",
    "county_adj = pd.read_csv('../data/countyadj_NY.csv', index_col = 0)\n",
    "models = ['acs', 'pep', 'worldpop']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "U-Nmbq-0wgYy"
   },
   "source": [
    "# Default Configs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "fY1Z6ccs2XUP"
   },
   "outputs": [],
   "source": [
    "# MCMC configs.\n",
    "mcmc_step_size=0.1 # @param\n",
    "mcmc_sample_size=500 # @param\n",
    "mcmc_num_steps=10_000 # @param\n",
    "mcmc_burnin=2_500 # @param\n",
    "mcmc_nchain=10 # @param\n",
    "mcmc_seed=0 # @param\n",
    "\n",
    "DEFAULT_MCMC_CONFIG = dict(step_size=mcmc_step_size, \n",
    "                           num_steps=mcmc_sample_size, \n",
    "                           burnin=mcmc_burnin, \n",
    "                           nchain=mcmc_nchain, \n",
    "                           seed=mcmc_seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bayesian Model Averaging\n",
    "\n",
    "A Bayesian ensemble model where ensemble weights $w_k's$ are parameterized by Gaussian process priors:\n",
    "\n",
    "$y \\sim N(\\mu(x), \\sigma^2)$ \n",
    "\n",
    "$\\mu(x) = \\sum_{k=1}^K w_k(x) * m_k(x) \\quad$  where $\\{m_k\\}_{k=1}^K$ are base model predictions.\n",
    "\n",
    "$w(x) = softmax(f(x)) \\qquad\\;\\;\\;$ where $w=[w_1, \\dots, w_K]$ and $f=[f_1, \\dots, f_K]$\n",
    "\n",
    "$f \\stackrel{i.i.d.}{\\sim} GaussianProcess(0, k)$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run MCMC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:135: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n",
      "<>:142: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n",
      "<>:158: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n",
      "<>:135: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n",
      "<>:142: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n",
      "<>:158: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n",
      "C:\\Users\\Admin-Dell\\AppData\\Local\\Temp\\ipykernel_31496\\2552605282.py:135: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n",
      "  if kernel_type is 'hmc':\n",
      "C:\\Users\\Admin-Dell\\AppData\\Local\\Temp\\ipykernel_31496\\2552605282.py:142: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n",
      "  if kernel_type is 'hmc':\n",
      "C:\\Users\\Admin-Dell\\AppData\\Local\\Temp\\ipykernel_31496\\2552605282.py:158: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n",
      "  if step_adaptor_type is 'simple':\n"
     ]
    }
   ],
   "source": [
    "#### Makes the MCMC sampler (with the log probability function!)\n",
    "def prepare_mcmc_CAR():\n",
    "  \"\"\"prepares the initial state and log prob function\"\"\"\n",
    "  Q = (1/tau2)*(np.diag(county_adj.sum(axis=1)) - rho*county_adj)\n",
    "  Q = tf.constant(Q, dtype = tf.float32)\n",
    "  init_state = tf.constant(np.array([mv_normal_sample(precision_matrix = Q, num_models = 3) for i in range(nchain)]),\n",
    "                           dtype = tf.float32)\n",
    "\n",
    "  return init_state, target_log_prob_fn_CAR\n",
    "\n",
    "def run_mcmc_CAR(init_state: Optional[List[tf.Tensor]] = None,\n",
    "             target_log_prob_fn: Optional[Callable[..., tf.Tensor]] = None, \n",
    "             model_dist: Optional[List[tfd.Distribution]] = None,      \n",
    "             y: Optional[tf.Tensor] = None,\n",
    "             sample_size: int = 500, \n",
    "             nchain: int = 10,             \n",
    "             num_steps: int = 500, \n",
    "             burnin: int = 100, \n",
    "             step_size: float = .1, \n",
    "             seed: int = 0, \n",
    "             debug_mode: bool = False,\n",
    "             **mcmc_kwargs):\n",
    "  \"\"\"Executes MCMC training for a given model posterior.\n",
    "  \n",
    "  Args:\n",
    "    target_log_prob_fn: The log likelihood function of modle posterior.\n",
    "      If not provided, then a default set of (init_state, target_log_prob_fn)\n",
    "      will be generated by `prepare_mcmc`.    \n",
    "    init_state: The initial states to the MCMC sampler, a list of tf.tensors \n",
    "      with shape (num_chains, num_variables). If not provided, then a default \n",
    "      set of (init_state, target_log_prob_fn) will be generated by \n",
    "      `prepare_mcmc`.\n",
    "    model_dist: The model posterior distribution to be used by `prepare_mcmc`. \n",
    "      Must be provided if init_state or target_log_prob_fn is None.\n",
    "    y: The output variable with shape (batch_size, ) to be used by \n",
    "      `prepare_mcmc`.  Must be provided if init_state or target_log_prob_fn is\n",
    "       None.\n",
    "    sample_size: The number of the final MCMC samples to return after thinning\n",
    "      the gathered MCMC samples.\n",
    "    n_chain: The number of MCMC chain in sampling.\n",
    "    num_steps: The number of total MCMC samples to generate.\n",
    "    burnin: The length of the burn-in period for MCMC warmup.\n",
    "    seed: The random seed for MCMC sampling.\n",
    "    debug_mode: If True. also return the original unmixed samples.\n",
    "    **mcmc_kwargs: Additional keyword arguments to pass to the low-level MCMC\n",
    "      function.\n",
    "\n",
    "  Return:\n",
    "    mixed_samples: A list of posterior samples with shapes [sample_size, ...]\n",
    "      for each variable in the model posterior. \n",
    "    sampler_stat: diagnostic statistics of the MCMC chain, which contains \n",
    "      the step size and the proposal acceptance of each HMC step.\n",
    "  \"\"\"\n",
    "  # Prepares initial states and model log likelihoods for MCMC.\n",
    "  if init_state is None or target_log_prob_fn is None:\n",
    "    # By default, sample first parameter of a two-parameter model (W, y).\n",
    "    init_state, target_log_prob_fn = prepare_mcmc_CAR(\n",
    "        model_dist, y, nchain=nchain)\n",
    "  else:\n",
    "    nchain = init_state.shape[0]\n",
    "    \n",
    "  # Perform MCMC.\n",
    "  chain_samples, sampler_stat = run_chain_CAR(\n",
    "      init_state=init_state, \n",
    "      step_size=step_size,\n",
    "      target_log_prob_fn=target_log_prob_fn,\n",
    "      num_steps=num_steps, \n",
    "      burnin=burnin, \n",
    "      seed=seed,\n",
    "      **mcmc_kwargs)\n",
    "  # Clear tf.function cache.\n",
    "  try:\n",
    "    try:\n",
    "      run_chain._stateful_fn._function_cache.clear()\n",
    "    except:\n",
    "      run_chain._stateful_fn._function_cache.primary.clear()\n",
    "  except:\n",
    "    print('no cache clearing')\n",
    "\n",
    "  # Thinning.\n",
    "  sample_size_per_chain = int(sample_size / nchain)\n",
    "  sample_ids = np.linspace(\n",
    "      0, num_steps-1, sample_size_per_chain).astype(int)\n",
    "  chain_samples_thinned = chain_samples.numpy()[sample_ids]\n",
    "\n",
    "  # Mix examples from different chains, \n",
    "  # Shape [param_dim_1, param_dim_2, num_mcmc_samples].\n",
    "  mixed_samples = mix_chain_samples(chain_samples_thinned)\n",
    "\n",
    "  # Check acceptance probability.\n",
    "  p_accept = tf.math.exp(tfp.math.reduce_logmeanexp(\n",
    "    tf.minimum(sampler_stat[-1], 0.)))\n",
    "  print(f'Acceptance Ratio: {p_accept}')\n",
    "  \n",
    "  if debug_mode:\n",
    "    return mixed_samples, chain_samples, sampler_stat\n",
    "  return mixed_samples, sampler_stat\n",
    "\n",
    "def run_chain_CAR(init_state: List[tf.Tensor], \n",
    "              step_size: float, \n",
    "              target_log_prob_fn: Callable[..., tf.Tensor], \n",
    "              num_steps: int = 500, \n",
    "              burnin: int = 100, \n",
    "              seed: int = 0,\n",
    "              kernel_type: str = \"hmc\",\n",
    "              step_adaptor_type: str = \"simple\"\n",
    "              ) -> Union[List[tf.Tensor], Tuple[tf.Tensor]]:\n",
    "  \"\"\"Low-level function that runs MCMC sampling for a given model posterior.\n",
    "  \n",
    "  Args:\n",
    "    init_state: The initial state for the MCMC sampler.\n",
    "    step_size: The step size of a Hamiltonian Monte Carlo step.\n",
    "    target_log_prob_fn: The log likelihood function for model posterior.\n",
    "    num_steps: The number of total MCMC samples to return.\n",
    "    burnin: The length of the burn-in period for MCMC warmup.\n",
    "    seed: The random seed for MCMC sampling.\n",
    "    kernel_type: Type of MCMC kernel to use, either ('hmc', 'nuts').\n",
    "    step_adaptor_type: Type of MCMC kernel to use, one of \n",
    "      ('simple', 'dual_averaging').\n",
    "\n",
    "  Returns:\n",
    "    chain_state: Posterior sample from all MCMC chains.\n",
    "    sampler stat: Sampling statistics, currently (step_size, acceptance ratio).\n",
    "  \"\"\"\n",
    "  if kernel_type not in ('hmc', 'nuts'):\n",
    "    raise ValueError(\n",
    "        f\"kernel_type {kernel_type} must be one of ('hmc', 'nuts').\")\n",
    "\n",
    "  if step_adaptor_type not in ('simple', 'dual_averaging'):\n",
    "    raise ValueError(\n",
    "        f\"step_adaptor_type {step_adaptor_type} must be one of \"\n",
    "        \"('simple', 'dual_averaging').\")\n",
    "\n",
    "  def trace_fn(_, pkr): \n",
    "    if kernel_type is 'hmc':\n",
    "      step_size = pkr.inner_results.accepted_results.step_size\n",
    "    else:\n",
    "      step_size = pkr.inner_results.step_size\n",
    "\n",
    "    return (step_size, pkr.inner_results.log_accept_ratio)\n",
    "\n",
    "  if kernel_type is 'hmc':\n",
    "    kernel = tfp.mcmc.HamiltonianMonteCarlo(\n",
    "        target_log_prob_fn=target_log_prob_fn,\n",
    "        num_leapfrog_steps=5,\n",
    "        step_size=step_size)\n",
    "    step_adaptation_kwargs = dict()\n",
    "  else:\n",
    "    kernel = tfp.mcmc.NoUTurnSampler(\n",
    "        target_log_prob_fn=target_log_prob_fn,\n",
    "        step_size=step_size)\n",
    "    step_adaptation_kwargs = dict(\n",
    "        step_size_setter_fn=lambda pkr, new_step_size: pkr._replace(\n",
    "            step_size=new_step_size),\n",
    "        step_size_getter_fn=lambda pkr: pkr.step_size,\n",
    "        log_accept_prob_getter_fn=lambda pkr: pkr.log_accept_ratio,)\n",
    "\n",
    "  if step_adaptor_type is 'simple':\n",
    "    kernel = tfp.mcmc.SimpleStepSizeAdaptation(\n",
    "      inner_kernel=kernel, \n",
    "      num_adaptation_steps=burnin)\n",
    "  else:\n",
    "    kernel = tfp.mcmc.DualAveragingStepSizeAdaptation(\n",
    "      inner_kernel=kernel,\n",
    "      num_adaptation_steps=burnin,\n",
    "      target_accept_prob=0.75,\n",
    "      **step_adaptation_kwargs)\n",
    "\n",
    "  print(num_steps)\n",
    "  # Execute sampling.\n",
    "  chain_state, sampler_stat = tfp.mcmc.sample_chain(\n",
    "      num_results=num_steps,\n",
    "      num_burnin_steps=burnin,\n",
    "      current_state=init_state,\n",
    "      kernel=kernel,\n",
    "      trace_fn=trace_fn,\n",
    "      seed=seed)\n",
    "    \n",
    "  return chain_state, sampler_stat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "## This function was taken from online\n",
    "# Generate samples from a multi-variate normal distribution with provided precision matrix WITHOUT inverting\n",
    "def mv_normal_sample(mu=0, precision_matrix=None, num_models=1):\n",
    "\n",
    "    # Precision matrix must be a square matrix\n",
    "    assert precision_matrix.shape[0] == precision_matrix.shape[1], 'Precision matrix must be a square matrix'\n",
    "\n",
    "    dim = precision_matrix.shape[0]\n",
    "\n",
    "    chol_U = scipy.linalg.cholesky(precision_matrix, lower=False)\n",
    "\n",
    "    # Create num_models iid standard normal vectors\n",
    "    z_vector_matrix = np.random.normal(loc=0, scale=1, size=[num_models, dim])\n",
    "\n",
    "    # Sample from the MV normal with precision matrix by solving the Cholesky decomp for each normal vector\n",
    "    samples = np.squeeze(np.array(\n",
    "        [scipy.linalg.solve_triangular(a=chol_U, b=z_vector_matrix[i, :], unit_diagonal=False) + mu for i in\n",
    "         range(num_models)]))\n",
    "\n",
    "    return (np.transpose(samples))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([2, 62, 3])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# init state should is the CAR values at each county\n",
    "nchain = 2\n",
    "tau2 = 100\n",
    "rho = 0.3\n",
    "\n",
    "Q = (1/tau2)*(np.diag(county_adj.sum(axis=1)) - rho*county_adj)\n",
    "Q = tf.constant(Q, dtype = tf.float32)\n",
    "\n",
    "init_state = tf.constant(np.array([mv_normal_sample(precision_matrix = Q, num_models = 3) for i in range(nchain)]),\n",
    "                        dtype = tf.float32)\n",
    "init_state.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def target_log_prob_fn_CAR(phi):\n",
    "    print('sup')\n",
    "    \n",
    "    Q = (1/tau2)*(np.diag(county_adj.sum(axis=1)) - rho*county_adj)\n",
    "    Q = tf.constant(Q, dtype = tf.float32)\n",
    "        \n",
    "    ll = tf.Variable(0.)\n",
    "    for chain in range(phi.shape[0]):\n",
    "        # (1) Prob of the CAR random effect values\n",
    "        ll_chain = -0.5*tf.reduce_mean(tf.linalg.diag_part(\n",
    "            tf.linalg.matmul(phi[chain,:,:],tf.linalg.matmul(Q, phi[chain,:,:]), transpose_a = True))) \n",
    "        ll = ll + ll_chain\n",
    "    \n",
    "    # add in determinant values\n",
    "    log_det = tf.constant(np.linalg.slogdet(Q)[1], dtype = tf.float32)\n",
    "    ll = ll + 0.5*phi.shape[0]*len(models)*log_det\n",
    "    \n",
    "    # get exponentiated values and sum across models\n",
    "    exp_phi = tf.math.exp(phi)\n",
    "    exp_phi_rows = tf.reduce_sum(exp_phi, 2)\n",
    "    \n",
    "    # get model weights and calculate mean estimate\n",
    "    u = exp_phi/exp_phi_rows[...,None]\n",
    "      \n",
    "    tmp = training2010[models].values*u\n",
    "    n = tf.reduce_sum(tmp, axis = 2)\n",
    "    \n",
    "    # update the log likelihood \n",
    "    ll = ll + tf.reduce_sum([np.sum(training2010['census']*np.log(n[chain,:]) - n[chain,:]) for chain in range(phi.shape[0])])\n",
    "    \n",
    "    print(ll)\n",
    "    return(ll)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tf.config.list_physical_devices('GPU'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "mcmc_config = DEFAULT_MCMC_CONFIG.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'step_size': 0.1, 'num_steps': 10000, 'burnin': 2500, 'nchain': 10, 'seed': 0}"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#mcmc_config.update(dict(burnin = 2500, num_steps = 10000, nchain = 5))\n",
    "mcmc_config.update(dict(burnin = 2500, num_steps = 10000))\n",
    "mcmc_config"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Seems like this takes ~2.6s per num_steps\n",
    "Took 265s for num_steps = 100\n",
    "Took 51s for num_steps = 50\n",
    "102s for num_steps = 100\n",
    "262s for num_steps = 100 test\n",
    "12s for num_steps = 100 the improved test\n",
    "and 16m for num_steps = 10000 and nchain = 5! Great"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "from wrapper_functions import *\n",
    "#from my_functions import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function wrapper_functions.run_mcmc(init_state: Optional[List[tensorflow.python.framework.ops.Tensor]] = None, target_log_prob_fn: Optional[Callable[..., tensorflow.python.framework.ops.Tensor]] = None, model_dist: Optional[List[tensorflow_probability.python.distributions.distribution.Distribution]] = None, y: Optional[tensorflow.python.framework.ops.Tensor] = None, sample_size: int = 500, nchain: int = 10, num_steps: int = 500, burnin: int = 100, step_size: float = 0.1, seed: int = 0, debug_mode: bool = False, **mcmc_kwargs)>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run_mcmc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So with wrapper functions but my \"run_chain\" this does not work\n",
    "with wrapper functions but my \"run_chain\" and \"run_mcmc\" this works\n",
    "with wrapper functions but my \"run_mcmc\" this doesn't work\n",
    "\n",
    "So these both together are the problem? What? How could this be possible? I guess they both changed in some way? How? How did these change"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "500\n",
      "sup\n",
      "tf.Tensor(485968200.0, shape=(), dtype=float32)\n",
      "sup\n",
      "tf.Tensor(485968200.0, shape=(), dtype=float32)\n",
      "sup\n",
      "tf.Tensor(485968200.0, shape=(), dtype=float32)\n",
      "sup\n",
      "tf.Tensor(485968200.0, shape=(), dtype=float32)\n",
      "sup\n",
      "tf.Tensor(485968200.0, shape=(), dtype=float32)\n",
      "sup\n",
      "tf.Tensor(485968200.0, shape=(), dtype=float32)\n",
      "sup\n",
      "tf.Tensor(485968200.0, shape=(), dtype=float32)\n",
      "sup\n",
      "tf.Tensor(485968200.0, shape=(), dtype=float32)\n",
      "sup\n",
      "tf.Tensor(485968200.0, shape=(), dtype=float32)\n",
      "sup\n",
      "tf.Tensor(485968200.0, shape=(), dtype=float32)\n",
      "sup\n",
      "tf.Tensor(485968200.0, shape=(), dtype=float32)\n",
      "sup\n",
      "tf.Tensor(485968200.0, shape=(), dtype=float32)\n",
      "sup\n",
      "tf.Tensor(485968160.0, shape=(), dtype=float32)\n",
      "sup\n",
      "tf.Tensor(485968160.0, shape=(), dtype=float32)\n",
      "sup\n",
      "tf.Tensor(485968200.0, shape=(), dtype=float32)\n",
      "sup\n",
      "tf.Tensor(485968200.0, shape=(), dtype=float32)\n",
      "sup\n",
      "tf.Tensor(485968200.0, shape=(), dtype=float32)\n",
      "sup\n",
      "tf.Tensor(485968200.0, shape=(), dtype=float32)\n",
      "sup\n",
      "tf.Tensor(485968160.0, shape=(), dtype=float32)\n",
      "sup\n",
      "tf.Tensor(485968160.0, shape=(), dtype=float32)\n",
      "sup\n",
      "tf.Tensor(485968200.0, shape=(), dtype=float32)\n",
      "sup\n",
      "tf.Tensor(485968200.0, shape=(), dtype=float32)\n",
      "sup\n",
      "tf.Tensor(485968200.0, shape=(), dtype=float32)\n",
      "sup\n",
      "tf.Tensor(485968200.0, shape=(), dtype=float32)\n",
      "sup\n",
      "tf.Tensor(485968200.0, shape=(), dtype=float32)\n",
      "sup\n",
      "tf.Tensor(485968200.0, shape=(), dtype=float32)\n",
      "sup\n",
      "tf.Tensor(485968200.0, shape=(), dtype=float32)\n",
      "sup\n",
      "tf.Tensor(485968200.0, shape=(), dtype=float32)\n",
      "sup\n",
      "tf.Tensor(485968200.0, shape=(), dtype=float32)\n",
      "sup\n",
      "tf.Tensor(485968200.0, shape=(), dtype=float32)\n",
      "sup\n",
      "tf.Tensor(485968200.0, shape=(), dtype=float32)\n",
      "sup\n",
      "tf.Tensor(485968200.0, shape=(), dtype=float32)\n",
      "sup\n",
      "tf.Tensor(485968200.0, shape=(), dtype=float32)\n",
      "sup\n",
      "tf.Tensor(485968200.0, shape=(), dtype=float32)\n",
      "sup\n",
      "tf.Tensor(485968200.0, shape=(), dtype=float32)\n",
      "sup\n",
      "tf.Tensor(485968200.0, shape=(), dtype=float32)\n",
      "sup\n",
      "tf.Tensor(485968200.0, shape=(), dtype=float32)\n",
      "sup\n",
      "tf.Tensor(485968200.0, shape=(), dtype=float32)\n",
      "sup\n",
      "tf.Tensor(485968200.0, shape=(), dtype=float32)\n",
      "sup\n",
      "tf.Tensor(485968200.0, shape=(), dtype=float32)\n",
      "sup\n",
      "tf.Tensor(485968200.0, shape=(), dtype=float32)\n",
      "sup\n",
      "tf.Tensor(485968200.0, shape=(), dtype=float32)\n",
      "sup\n",
      "tf.Tensor(485968200.0, shape=(), dtype=float32)\n",
      "sup\n",
      "tf.Tensor(485968200.0, shape=(), dtype=float32)\n",
      "sup\n",
      "tf.Tensor(485968200.0, shape=(), dtype=float32)\n",
      "sup\n",
      "tf.Tensor(485968200.0, shape=(), dtype=float32)\n",
      "sup\n",
      "tf.Tensor(485968200.0, shape=(), dtype=float32)\n",
      "sup\n",
      "tf.Tensor(485968200.0, shape=(), dtype=float32)\n",
      "sup\n",
      "tf.Tensor(485968200.0, shape=(), dtype=float32)\n",
      "sup\n",
      "tf.Tensor(485968200.0, shape=(), dtype=float32)\n",
      "sup\n",
      "tf.Tensor(485968200.0, shape=(), dtype=float32)\n",
      "sup\n",
      "tf.Tensor(485968200.0, shape=(), dtype=float32)\n",
      "sup\n",
      "tf.Tensor(485968200.0, shape=(), dtype=float32)\n",
      "sup\n",
      "tf.Tensor(485968200.0, shape=(), dtype=float32)\n",
      "sup\n",
      "tf.Tensor(485968200.0, shape=(), dtype=float32)\n",
      "sup\n",
      "tf.Tensor(485968200.0, shape=(), dtype=float32)\n",
      "sup\n",
      "tf.Tensor(485968200.0, shape=(), dtype=float32)\n",
      "sup\n",
      "tf.Tensor(485968200.0, shape=(), dtype=float32)\n",
      "sup\n",
      "tf.Tensor(485968200.0, shape=(), dtype=float32)\n",
      "sup\n",
      "tf.Tensor(485968200.0, shape=(), dtype=float32)\n",
      "sup\n",
      "tf.Tensor(485968200.0, shape=(), dtype=float32)\n",
      "sup\n",
      "tf.Tensor(485968200.0, shape=(), dtype=float32)\n",
      "sup\n",
      "tf.Tensor(485968200.0, shape=(), dtype=float32)\n",
      "sup\n",
      "tf.Tensor(485968200.0, shape=(), dtype=float32)\n",
      "sup\n",
      "tf.Tensor(485968200.0, shape=(), dtype=float32)\n",
      "sup\n",
      "tf.Tensor(485968200.0, shape=(), dtype=float32)\n",
      "sup\n",
      "tf.Tensor(485968200.0, shape=(), dtype=float32)\n",
      "sup\n",
      "tf.Tensor(485968200.0, shape=(), dtype=float32)\n",
      "sup\n",
      "tf.Tensor(485968200.0, shape=(), dtype=float32)\n",
      "sup\n",
      "tf.Tensor(485968200.0, shape=(), dtype=float32)\n",
      "sup\n",
      "tf.Tensor(485968200.0, shape=(), dtype=float32)\n",
      "sup\n",
      "tf.Tensor(485968200.0, shape=(), dtype=float32)\n",
      "sup\n",
      "tf.Tensor(485968220.0, shape=(), dtype=float32)\n",
      "sup\n",
      "tf.Tensor(485968220.0, shape=(), dtype=float32)\n",
      "sup\n",
      "tf.Tensor(485968220.0, shape=(), dtype=float32)\n",
      "sup\n",
      "tf.Tensor(485968220.0, shape=(), dtype=float32)\n",
      "sup\n",
      "tf.Tensor(485968220.0, shape=(), dtype=float32)\n",
      "sup\n",
      "tf.Tensor(485968220.0, shape=(), dtype=float32)\n",
      "sup\n",
      "tf.Tensor(485968220.0, shape=(), dtype=float32)\n",
      "sup\n",
      "tf.Tensor(485968220.0, shape=(), dtype=float32)\n",
      "sup\n",
      "tf.Tensor(485968260.0, shape=(), dtype=float32)\n",
      "sup\n",
      "tf.Tensor(485968260.0, shape=(), dtype=float32)\n",
      "sup\n",
      "tf.Tensor(485968220.0, shape=(), dtype=float32)\n",
      "sup\n",
      "tf.Tensor(485968220.0, shape=(), dtype=float32)\n",
      "sup\n",
      "tf.Tensor(485968220.0, shape=(), dtype=float32)\n",
      "sup\n",
      "tf.Tensor(485968220.0, shape=(), dtype=float32)\n",
      "sup\n",
      "tf.Tensor(485968200.0, shape=(), dtype=float32)\n",
      "sup\n",
      "tf.Tensor(485968200.0, shape=(), dtype=float32)\n",
      "sup\n",
      "tf.Tensor(485968200.0, shape=(), dtype=float32)\n",
      "sup\n",
      "tf.Tensor(485968200.0, shape=(), dtype=float32)\n",
      "sup\n",
      "tf.Tensor(485968200.0, shape=(), dtype=float32)\n",
      "sup\n",
      "tf.Tensor(485968200.0, shape=(), dtype=float32)\n",
      "sup\n",
      "tf.Tensor(485968200.0, shape=(), dtype=float32)\n",
      "sup\n",
      "tf.Tensor(485968200.0, shape=(), dtype=float32)\n",
      "sup\n",
      "tf.Tensor(485968260.0, shape=(), dtype=float32)\n",
      "sup\n",
      "tf.Tensor(485968260.0, shape=(), dtype=float32)\n",
      "sup\n",
      "tf.Tensor(485968260.0, shape=(), dtype=float32)\n",
      "sup\n",
      "tf.Tensor(485968260.0, shape=(), dtype=float32)\n",
      "sup\n",
      "tf.Tensor(485968260.0, shape=(), dtype=float32)\n",
      "sup\n",
      "tf.Tensor(485968260.0, shape=(), dtype=float32)\n",
      "sup\n",
      "tf.Tensor(485968260.0, shape=(), dtype=float32)\n",
      "sup\n",
      "tf.Tensor(485968260.0, shape=(), dtype=float32)\n",
      "sup\n",
      "tf.Tensor(485968260.0, shape=(), dtype=float32)\n",
      "sup\n",
      "tf.Tensor(485968260.0, shape=(), dtype=float32)\n",
      "sup\n",
      "tf.Tensor(485968260.0, shape=(), dtype=float32)\n",
      "sup\n",
      "tf.Tensor(485968260.0, shape=(), dtype=float32)\n",
      "sup\n",
      "tf.Tensor(485968260.0, shape=(), dtype=float32)\n",
      "sup\n",
      "tf.Tensor(485968260.0, shape=(), dtype=float32)\n",
      "sup\n",
      "tf.Tensor(485968260.0, shape=(), dtype=float32)\n",
      "sup\n",
      "tf.Tensor(485968260.0, shape=(), dtype=float32)\n",
      "sup\n",
      "tf.Tensor(485968260.0, shape=(), dtype=float32)\n",
      "sup\n",
      "tf.Tensor(485968260.0, shape=(), dtype=float32)\n",
      "sup\n",
      "tf.Tensor(485968260.0, shape=(), dtype=float32)\n",
      "sup\n",
      "tf.Tensor(485968260.0, shape=(), dtype=float32)\n",
      "sup\n",
      "tf.Tensor(485968260.0, shape=(), dtype=float32)\n",
      "sup\n",
      "tf.Tensor(485968260.0, shape=(), dtype=float32)\n",
      "sup\n",
      "tf.Tensor(485968260.0, shape=(), dtype=float32)\n",
      "sup\n",
      "tf.Tensor(485968260.0, shape=(), dtype=float32)\n",
      "sup\n",
      "tf.Tensor(485968260.0, shape=(), dtype=float32)\n",
      "sup\n",
      "tf.Tensor(485968260.0, shape=(), dtype=float32)\n",
      "sup\n",
      "tf.Tensor(485968260.0, shape=(), dtype=float32)\n",
      "sup\n",
      "tf.Tensor(485968260.0, shape=(), dtype=float32)\n",
      "sup\n",
      "tf.Tensor(485968260.0, shape=(), dtype=float32)\n",
      "sup\n",
      "tf.Tensor(485968260.0, shape=(), dtype=float32)\n",
      "sup\n",
      "tf.Tensor(485968260.0, shape=(), dtype=float32)\n",
      "sup\n",
      "tf.Tensor(485968260.0, shape=(), dtype=float32)\n",
      "sup\n",
      "tf.Tensor(485968260.0, shape=(), dtype=float32)\n",
      "sup\n",
      "tf.Tensor(485968260.0, shape=(), dtype=float32)\n",
      "sup\n",
      "tf.Tensor(485968260.0, shape=(), dtype=float32)\n",
      "sup\n",
      "tf.Tensor(485968260.0, shape=(), dtype=float32)\n",
      "sup\n",
      "tf.Tensor(485968260.0, shape=(), dtype=float32)\n",
      "sup\n",
      "tf.Tensor(485968260.0, shape=(), dtype=float32)\n",
      "sup\n",
      "tf.Tensor(485968260.0, shape=(), dtype=float32)\n",
      "sup\n",
      "tf.Tensor(485968260.0, shape=(), dtype=float32)\n",
      "sup\n",
      "tf.Tensor(485968260.0, shape=(), dtype=float32)\n",
      "sup\n",
      "tf.Tensor(485968260.0, shape=(), dtype=float32)\n",
      "sup\n",
      "tf.Tensor(485968260.0, shape=(), dtype=float32)\n",
      "sup\n",
      "tf.Tensor(485968260.0, shape=(), dtype=float32)\n",
      "sup\n",
      "tf.Tensor(485968260.0, shape=(), dtype=float32)\n",
      "sup\n",
      "tf.Tensor(485968260.0, shape=(), dtype=float32)\n",
      "sup\n",
      "tf.Tensor(485968260.0, shape=(), dtype=float32)\n",
      "sup\n",
      "tf.Tensor(485968260.0, shape=(), dtype=float32)\n",
      "sup\n",
      "tf.Tensor(485968260.0, shape=(), dtype=float32)\n",
      "sup\n",
      "tf.Tensor(485968260.0, shape=(), dtype=float32)\n",
      "sup\n",
      "tf.Tensor(485968260.0, shape=(), dtype=float32)\n",
      "sup\n",
      "tf.Tensor(485968260.0, shape=(), dtype=float32)\n",
      "sup\n",
      "tf.Tensor(485968260.0, shape=(), dtype=float32)\n",
      "sup\n",
      "tf.Tensor(485968260.0, shape=(), dtype=float32)\n",
      "sup\n",
      "tf.Tensor(485968260.0, shape=(), dtype=float32)\n",
      "sup\n",
      "tf.Tensor(485968260.0, shape=(), dtype=float32)\n",
      "sup\n",
      "tf.Tensor(485968260.0, shape=(), dtype=float32)\n",
      "sup\n",
      "tf.Tensor(485968260.0, shape=(), dtype=float32)\n",
      "sup\n",
      "tf.Tensor(485968260.0, shape=(), dtype=float32)\n",
      "sup\n",
      "tf.Tensor(485968260.0, shape=(), dtype=float32)\n",
      "sup\n",
      "tf.Tensor(485968260.0, shape=(), dtype=float32)\n",
      "sup\n",
      "tf.Tensor(485968260.0, shape=(), dtype=float32)\n",
      "sup\n",
      "tf.Tensor(485968260.0, shape=(), dtype=float32)\n",
      "sup\n",
      "tf.Tensor(485968260.0, shape=(), dtype=float32)\n",
      "sup\n",
      "tf.Tensor(485968260.0, shape=(), dtype=float32)\n",
      "sup\n",
      "tf.Tensor(485968260.0, shape=(), dtype=float32)\n",
      "sup\n",
      "tf.Tensor(485968260.0, shape=(), dtype=float32)\n",
      "sup\n",
      "tf.Tensor(485968260.0, shape=(), dtype=float32)\n",
      "sup\n",
      "tf.Tensor(485968260.0, shape=(), dtype=float32)\n",
      "sup\n",
      "tf.Tensor(485968260.0, shape=(), dtype=float32)\n",
      "sup\n",
      "tf.Tensor(485968260.0, shape=(), dtype=float32)\n",
      "sup\n",
      "tf.Tensor(485968260.0, shape=(), dtype=float32)\n",
      "sup\n",
      "tf.Tensor(485968260.0, shape=(), dtype=float32)\n",
      "sup\n",
      "tf.Tensor(485968260.0, shape=(), dtype=float32)\n",
      "sup\n",
      "tf.Tensor(485968260.0, shape=(), dtype=float32)\n",
      "sup\n",
      "tf.Tensor(485968260.0, shape=(), dtype=float32)\n",
      "sup\n",
      "tf.Tensor(485968260.0, shape=(), dtype=float32)\n",
      "sup\n",
      "tf.Tensor(485968260.0, shape=(), dtype=float32)\n",
      "sup\n",
      "tf.Tensor(485968260.0, shape=(), dtype=float32)\n",
      "sup\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(485968260.0, shape=(), dtype=float32)\n",
      "sup\n",
      "tf.Tensor(485968260.0, shape=(), dtype=float32)\n",
      "sup\n",
      "tf.Tensor(485968260.0, shape=(), dtype=float32)\n",
      "sup\n",
      "tf.Tensor(485968260.0, shape=(), dtype=float32)\n",
      "sup\n",
      "tf.Tensor(485968260.0, shape=(), dtype=float32)\n",
      "sup\n",
      "tf.Tensor(485968260.0, shape=(), dtype=float32)\n",
      "sup\n",
      "tf.Tensor(485968260.0, shape=(), dtype=float32)\n",
      "sup\n",
      "tf.Tensor(485968260.0, shape=(), dtype=float32)\n",
      "sup\n",
      "tf.Tensor(485968260.0, shape=(), dtype=float32)\n",
      "sup\n",
      "tf.Tensor(485968260.0, shape=(), dtype=float32)\n",
      "sup\n",
      "tf.Tensor(485968260.0, shape=(), dtype=float32)\n",
      "sup\n",
      "tf.Tensor(485968260.0, shape=(), dtype=float32)\n",
      "sup\n",
      "tf.Tensor(485968260.0, shape=(), dtype=float32)\n",
      "sup\n",
      "tf.Tensor(485968260.0, shape=(), dtype=float32)\n",
      "sup\n",
      "tf.Tensor(485968260.0, shape=(), dtype=float32)\n",
      "sup\n",
      "tf.Tensor(485968260.0, shape=(), dtype=float32)\n",
      "sup\n",
      "tf.Tensor(485968260.0, shape=(), dtype=float32)\n",
      "sup\n",
      "tf.Tensor(485968300.0, shape=(), dtype=float32)\n",
      "sup\n",
      "tf.Tensor(485968300.0, shape=(), dtype=float32)\n",
      "sup\n",
      "tf.Tensor(485968260.0, shape=(), dtype=float32)\n",
      "sup\n",
      "tf.Tensor(485968260.0, shape=(), dtype=float32)\n",
      "sup\n",
      "tf.Tensor(485968300.0, shape=(), dtype=float32)\n",
      "sup\n",
      "tf.Tensor(485968300.0, shape=(), dtype=float32)\n",
      "sup\n",
      "tf.Tensor(485968300.0, shape=(), dtype=float32)\n",
      "sup\n",
      "tf.Tensor(485968300.0, shape=(), dtype=float32)\n",
      "sup\n",
      "tf.Tensor(485968300.0, shape=(), dtype=float32)\n",
      "sup\n",
      "tf.Tensor(485968300.0, shape=(), dtype=float32)\n",
      "sup\n",
      "tf.Tensor(485968300.0, shape=(), dtype=float32)\n",
      "sup\n",
      "tf.Tensor(485968300.0, shape=(), dtype=float32)\n",
      "sup\n",
      "tf.Tensor(485968260.0, shape=(), dtype=float32)\n",
      "sup\n",
      "tf.Tensor(485968260.0, shape=(), dtype=float32)\n",
      "sup\n",
      "tf.Tensor(485968300.0, shape=(), dtype=float32)\n",
      "sup\n",
      "tf.Tensor(485968300.0, shape=(), dtype=float32)\n",
      "sup\n",
      "tf.Tensor(485968300.0, shape=(), dtype=float32)\n",
      "sup\n",
      "tf.Tensor(485968300.0, shape=(), dtype=float32)\n",
      "sup\n",
      "tf.Tensor(485968300.0, shape=(), dtype=float32)\n",
      "sup\n",
      "tf.Tensor(485968300.0, shape=(), dtype=float32)\n",
      "sup\n",
      "tf.Tensor(485968260.0, shape=(), dtype=float32)\n",
      "sup\n",
      "tf.Tensor(485968260.0, shape=(), dtype=float32)\n",
      "sup\n",
      "tf.Tensor(485968260.0, shape=(), dtype=float32)\n",
      "sup\n",
      "tf.Tensor(485968260.0, shape=(), dtype=float32)\n",
      "sup\n",
      "tf.Tensor(485968260.0, shape=(), dtype=float32)\n",
      "sup\n",
      "tf.Tensor(485968260.0, shape=(), dtype=float32)\n",
      "sup\n",
      "tf.Tensor(485968260.0, shape=(), dtype=float32)\n",
      "sup\n",
      "tf.Tensor(485968260.0, shape=(), dtype=float32)\n",
      "sup\n",
      "tf.Tensor(485968260.0, shape=(), dtype=float32)\n",
      "sup\n",
      "tf.Tensor(485968260.0, shape=(), dtype=float32)\n",
      "sup\n",
      "tf.Tensor(485968300.0, shape=(), dtype=float32)\n",
      "sup\n",
      "tf.Tensor(485968300.0, shape=(), dtype=float32)\n",
      "sup\n",
      "tf.Tensor(485968300.0, shape=(), dtype=float32)\n",
      "sup\n",
      "tf.Tensor(485968300.0, shape=(), dtype=float32)\n",
      "sup\n",
      "tf.Tensor(485968300.0, shape=(), dtype=float32)\n",
      "sup\n",
      "tf.Tensor(485968300.0, shape=(), dtype=float32)\n",
      "sup\n",
      "tf.Tensor(485968300.0, shape=(), dtype=float32)\n",
      "sup\n",
      "tf.Tensor(485968300.0, shape=(), dtype=float32)\n",
      "sup\n",
      "tf.Tensor(485968300.0, shape=(), dtype=float32)\n",
      "sup\n",
      "tf.Tensor(485968300.0, shape=(), dtype=float32)\n",
      "sup\n",
      "tf.Tensor(485968300.0, shape=(), dtype=float32)\n",
      "sup\n",
      "tf.Tensor(485968300.0, shape=(), dtype=float32)\n",
      "sup\n",
      "tf.Tensor(485968300.0, shape=(), dtype=float32)\n",
      "sup\n",
      "tf.Tensor(485968300.0, shape=(), dtype=float32)\n",
      "sup\n",
      "tf.Tensor(485968320.0, shape=(), dtype=float32)\n",
      "sup\n",
      "tf.Tensor(485968320.0, shape=(), dtype=float32)\n",
      "sup\n",
      "tf.Tensor(485968300.0, shape=(), dtype=float32)\n",
      "sup\n",
      "tf.Tensor(485968300.0, shape=(), dtype=float32)\n",
      "sup\n",
      "tf.Tensor(485968260.0, shape=(), dtype=float32)\n",
      "sup\n",
      "tf.Tensor(485968260.0, shape=(), dtype=float32)\n",
      "sup\n",
      "tf.Tensor(485968220.0, shape=(), dtype=float32)\n",
      "sup\n",
      "tf.Tensor(485968220.0, shape=(), dtype=float32)\n",
      "sup\n",
      "tf.Tensor(485968300.0, shape=(), dtype=float32)\n",
      "sup\n",
      "tf.Tensor(485968300.0, shape=(), dtype=float32)\n",
      "sup\n",
      "tf.Tensor(485968320.0, shape=(), dtype=float32)\n",
      "sup\n",
      "tf.Tensor(485968320.0, shape=(), dtype=float32)\n",
      "sup\n",
      "tf.Tensor(485968300.0, shape=(), dtype=float32)\n",
      "sup\n",
      "tf.Tensor(485968300.0, shape=(), dtype=float32)\n",
      "sup\n",
      "tf.Tensor(485968260.0, shape=(), dtype=float32)\n",
      "sup\n",
      "tf.Tensor(485968260.0, shape=(), dtype=float32)\n",
      "sup\n",
      "tf.Tensor(485968260.0, shape=(), dtype=float32)\n",
      "sup\n",
      "tf.Tensor(485968260.0, shape=(), dtype=float32)\n",
      "sup\n",
      "tf.Tensor(485968260.0, shape=(), dtype=float32)\n",
      "sup\n",
      "tf.Tensor(485968260.0, shape=(), dtype=float32)\n",
      "sup\n",
      "tf.Tensor(485968300.0, shape=(), dtype=float32)\n",
      "sup\n",
      "tf.Tensor(485968300.0, shape=(), dtype=float32)\n",
      "sup\n",
      "tf.Tensor(485968300.0, shape=(), dtype=float32)\n",
      "sup\n",
      "tf.Tensor(485968300.0, shape=(), dtype=float32)\n",
      "sup\n",
      "tf.Tensor(485968300.0, shape=(), dtype=float32)\n",
      "sup\n",
      "tf.Tensor(485968300.0, shape=(), dtype=float32)\n",
      "sup\n",
      "tf.Tensor(485968260.0, shape=(), dtype=float32)\n",
      "sup\n",
      "tf.Tensor(485968260.0, shape=(), dtype=float32)\n",
      "sup\n",
      "tf.Tensor(485968300.0, shape=(), dtype=float32)\n",
      "sup\n",
      "tf.Tensor(485968300.0, shape=(), dtype=float32)\n",
      "sup\n",
      "tf.Tensor(485968260.0, shape=(), dtype=float32)\n",
      "sup\n",
      "tf.Tensor(485968260.0, shape=(), dtype=float32)\n",
      "sup\n",
      "tf.Tensor(485968300.0, shape=(), dtype=float32)\n",
      "sup\n",
      "tf.Tensor(485968300.0, shape=(), dtype=float32)\n",
      "sup\n",
      "tf.Tensor(485968300.0, shape=(), dtype=float32)\n",
      "sup\n",
      "tf.Tensor(485968300.0, shape=(), dtype=float32)\n",
      "sup\n",
      "tf.Tensor(485968300.0, shape=(), dtype=float32)\n",
      "sup\n",
      "tf.Tensor(485968300.0, shape=(), dtype=float32)\n",
      "sup\n",
      "tf.Tensor(485968260.0, shape=(), dtype=float32)\n",
      "sup\n",
      "tf.Tensor(485968260.0, shape=(), dtype=float32)\n",
      "sup\n",
      "tf.Tensor(485968260.0, shape=(), dtype=float32)\n",
      "sup\n",
      "tf.Tensor(485968260.0, shape=(), dtype=float32)\n",
      "sup\n",
      "tf.Tensor(485968260.0, shape=(), dtype=float32)\n",
      "sup\n",
      "tf.Tensor(485968260.0, shape=(), dtype=float32)\n",
      "sup\n",
      "tf.Tensor(485968220.0, shape=(), dtype=float32)\n",
      "sup\n",
      "tf.Tensor(485968220.0, shape=(), dtype=float32)\n",
      "sup\n",
      "tf.Tensor(485968260.0, shape=(), dtype=float32)\n",
      "sup\n",
      "tf.Tensor(485968260.0, shape=(), dtype=float32)\n",
      "sup\n",
      "tf.Tensor(485968260.0, shape=(), dtype=float32)\n",
      "sup\n",
      "tf.Tensor(485968260.0, shape=(), dtype=float32)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_31496\\116055622.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mt0\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mperf_counter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m CAR_samples, chain_samples, sampler_stat = run_mcmc_CAR(init_state=init_state,\n\u001b[0m\u001b[0;32m      3\u001b[0m                              \u001b[0mtarget_log_prob_fn\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtarget_log_prob_fn_CAR\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m                              \u001b[0mdebug_mode\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m                              **mcmc_config)  \n",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_31496\\2552605282.py\u001b[0m in \u001b[0;36mrun_mcmc_CAR\u001b[1;34m(init_state, target_log_prob_fn, model_dist, y, sample_size, nchain, num_steps, burnin, step_size, seed, debug_mode, **mcmc_kwargs)\u001b[0m\n\u001b[0;32m     61\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     62\u001b[0m   \u001b[1;31m# Perform MCMC.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 63\u001b[1;33m   chain_samples, sampler_stat = run_chain_CAR(\n\u001b[0m\u001b[0;32m     64\u001b[0m       \u001b[0minit_state\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minit_state\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     65\u001b[0m       \u001b[0mstep_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mstep_size\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_31496\\2552605282.py\u001b[0m in \u001b[0;36mrun_chain_CAR\u001b[1;34m(init_state, step_size, target_log_prob_fn, num_steps, burnin, seed, kernel_type, step_adaptor_type)\u001b[0m\n\u001b[0;32m    169\u001b[0m   \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnum_steps\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    170\u001b[0m   \u001b[1;31m# Execute sampling.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 171\u001b[1;33m   chain_state, sampler_stat = tfp.mcmc.sample_chain(\n\u001b[0m\u001b[0;32m    172\u001b[0m       \u001b[0mnum_results\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnum_steps\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    173\u001b[0m       \u001b[0mnum_burnin_steps\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mburnin\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow_probability\\python\\mcmc\\sample.py\u001b[0m in \u001b[0;36msample_chain\u001b[1;34m(num_results, current_state, previous_kernel_results, kernel, num_burnin_steps, num_steps_between_results, trace_fn, return_final_kernel_results, parallel_iterations, seed, name)\u001b[0m\n\u001b[0;32m    357\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0mseed\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnext_state\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcurrent_kernel_results\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    358\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 359\u001b[1;33m     (_, _, final_kernel_results), (all_states, trace) = loop_util.trace_scan(\n\u001b[0m\u001b[0;32m    360\u001b[0m         \u001b[0mloop_fn\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0m_trace_scan_fn\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    361\u001b[0m         \u001b[0minitial_state\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mseed\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcurrent_state\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mprevious_kernel_results\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow_probability\\python\\internal\\loop_util.py\u001b[0m in \u001b[0;36mtrace_scan\u001b[1;34m(loop_fn, initial_state, elems, trace_fn, trace_criterion_fn, static_trace_allocation_size, condition_fn, parallel_iterations, name)\u001b[0m\n\u001b[0;32m    220\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0mi\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstate\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnum_steps_traced\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrace_arrays\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    221\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 222\u001b[1;33m     _, final_state, _, trace_arrays = tf.while_loop(\n\u001b[0m\u001b[0;32m    223\u001b[0m         \u001b[0mcond\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcondition_fn\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mcondition_fn\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32melse\u001b[0m \u001b[1;32mlambda\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0m_\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    224\u001b[0m         \u001b[0mbody\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0m_body\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\util\\deprecation.py\u001b[0m in \u001b[0;36mnew_func\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    627\u001b[0m                   \u001b[0mfunc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__module__\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0marg_name\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0marg_value\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'in a future version'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    628\u001b[0m                   if date is None else ('after %s' % date), instructions)\n\u001b[1;32m--> 629\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    630\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    631\u001b[0m     doc = _add_deprecated_arg_value_notice_to_docstring(\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\control_flow_ops.py\u001b[0m in \u001b[0;36mwhile_loop_v2\u001b[1;34m(cond, body, loop_vars, shape_invariants, parallel_iterations, back_prop, swap_memory, maximum_iterations, name)\u001b[0m\n\u001b[0;32m   2514\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2515\u001b[0m   \"\"\"\n\u001b[1;32m-> 2516\u001b[1;33m   return while_loop(\n\u001b[0m\u001b[0;32m   2517\u001b[0m       \u001b[0mcond\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcond\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2518\u001b[0m       \u001b[0mbody\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mbody\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\control_flow_ops.py\u001b[0m in \u001b[0;36mwhile_loop\u001b[1;34m(cond, body, loop_vars, shape_invariants, parallel_iterations, back_prop, swap_memory, name, maximum_iterations, return_same_structure)\u001b[0m\n\u001b[0;32m   2763\u001b[0m                                               list(loop_vars))\n\u001b[0;32m   2764\u001b[0m       \u001b[1;32mwhile\u001b[0m \u001b[0mcond\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mloop_vars\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2765\u001b[1;33m         \u001b[0mloop_vars\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbody\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mloop_vars\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2766\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mtry_to_pack\u001b[0m \u001b[1;32mand\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mloop_vars\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_basetuple\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2767\u001b[0m           \u001b[0mpacked\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\control_flow_ops.py\u001b[0m in \u001b[0;36m<lambda>\u001b[1;34m(i, lv)\u001b[0m\n\u001b[0;32m   2754\u001b[0m         cond = lambda i, lv: (  # pylint: disable=g-long-lambda\n\u001b[0;32m   2755\u001b[0m             math_ops.logical_and(i < maximum_iterations, orig_cond(*lv)))\n\u001b[1;32m-> 2756\u001b[1;33m         \u001b[0mbody\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mlambda\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlv\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mi\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0morig_body\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mlv\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2757\u001b[0m       \u001b[0mtry_to_pack\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2758\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow_probability\\python\\internal\\loop_util.py\u001b[0m in \u001b[0;36m_body\u001b[1;34m(i, state, num_steps_traced, trace_arrays)\u001b[0m\n\u001b[0;32m    210\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_body\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstate\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnum_steps_traced\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrace_arrays\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    211\u001b[0m       \u001b[0melem\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0melems_array\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 212\u001b[1;33m       \u001b[0mstate\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mloop_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0melem\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    213\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    214\u001b[0m       trace_arrays, num_steps_traced = ps.cond(\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow_probability\\python\\mcmc\\sample.py\u001b[0m in \u001b[0;36m_trace_scan_fn\u001b[1;34m(seed_state_and_results, num_steps)\u001b[0m\n\u001b[0;32m    350\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    351\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_trace_scan_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mseed_state_and_results\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnum_steps\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 352\u001b[1;33m       seed, next_state, current_kernel_results = loop_util.smart_for_loop(\n\u001b[0m\u001b[0;32m    353\u001b[0m           \u001b[0mloop_num_iter\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnum_steps\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    354\u001b[0m           \u001b[0mbody_fn\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0m_seeded_one_step\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow_probability\\python\\internal\\loop_util.py\u001b[0m in \u001b[0;36msmart_for_loop\u001b[1;34m(loop_num_iter, body_fn, initial_loop_vars, parallel_iterations, unroll_threshold, name)\u001b[0m\n\u001b[0;32m     95\u001b[0m       \u001b[1;31m# where while/LoopCond needs it.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     96\u001b[0m       \u001b[0mloop_num_iter\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcast\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mloop_num_iter\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mint32\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 97\u001b[1;33m       return tf.while_loop(\n\u001b[0m\u001b[0;32m     98\u001b[0m           \u001b[0mcond\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mlambda\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mi\u001b[0m \u001b[1;33m<\u001b[0m \u001b[0mloop_num_iter\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     99\u001b[0m           \u001b[0mbody\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mlambda\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbody_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\util\\deprecation.py\u001b[0m in \u001b[0;36mnew_func\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    627\u001b[0m                   \u001b[0mfunc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__module__\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0marg_name\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0marg_value\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'in a future version'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    628\u001b[0m                   if date is None else ('after %s' % date), instructions)\n\u001b[1;32m--> 629\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    630\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    631\u001b[0m     doc = _add_deprecated_arg_value_notice_to_docstring(\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\control_flow_ops.py\u001b[0m in \u001b[0;36mwhile_loop_v2\u001b[1;34m(cond, body, loop_vars, shape_invariants, parallel_iterations, back_prop, swap_memory, maximum_iterations, name)\u001b[0m\n\u001b[0;32m   2514\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2515\u001b[0m   \"\"\"\n\u001b[1;32m-> 2516\u001b[1;33m   return while_loop(\n\u001b[0m\u001b[0;32m   2517\u001b[0m       \u001b[0mcond\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcond\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2518\u001b[0m       \u001b[0mbody\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mbody\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\control_flow_ops.py\u001b[0m in \u001b[0;36mwhile_loop\u001b[1;34m(cond, body, loop_vars, shape_invariants, parallel_iterations, back_prop, swap_memory, name, maximum_iterations, return_same_structure)\u001b[0m\n\u001b[0;32m   2763\u001b[0m                                               list(loop_vars))\n\u001b[0;32m   2764\u001b[0m       \u001b[1;32mwhile\u001b[0m \u001b[0mcond\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mloop_vars\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2765\u001b[1;33m         \u001b[0mloop_vars\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbody\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mloop_vars\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2766\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mtry_to_pack\u001b[0m \u001b[1;32mand\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mloop_vars\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_basetuple\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2767\u001b[0m           \u001b[0mpacked\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow_probability\\python\\internal\\loop_util.py\u001b[0m in \u001b[0;36m<lambda>\u001b[1;34m(i, *args)\u001b[0m\n\u001b[0;32m     97\u001b[0m       return tf.while_loop(\n\u001b[0;32m     98\u001b[0m           \u001b[0mcond\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mlambda\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mi\u001b[0m \u001b[1;33m<\u001b[0m \u001b[0mloop_num_iter\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 99\u001b[1;33m           \u001b[0mbody\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mlambda\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbody_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    100\u001b[0m           \u001b[0mloop_vars\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mint32\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0minitial_loop_vars\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    101\u001b[0m           \u001b[0mparallel_iterations\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mparallel_iterations\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow_probability\\python\\mcmc\\sample.py\u001b[0m in \u001b[0;36m_seeded_one_step\u001b[1;34m(seed, *state_and_results)\u001b[0m\n\u001b[0;32m    347\u001b[0m       \u001b[0mone_step_kwargs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mseed\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mstep_seed\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mis_seeded\u001b[0m \u001b[1;32melse\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    348\u001b[0m       return [passalong_seed] + list(\n\u001b[1;32m--> 349\u001b[1;33m           kernel.one_step(*state_and_results, **one_step_kwargs))\n\u001b[0m\u001b[0;32m    350\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    351\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_trace_scan_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mseed_state_and_results\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnum_steps\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow_probability\\python\\mcmc\\simple_step_size_adaptation.py\u001b[0m in \u001b[0;36mone_step\u001b[1;34m(self, current_state, previous_kernel_results, seed)\u001b[0m\n\u001b[0;32m    352\u001b[0m       \u001b[1;31m# Step the inner kernel.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    353\u001b[0m       \u001b[0minner_kwargs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;33m}\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mseed\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32melse\u001b[0m \u001b[0mdict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mseed\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mseed\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 354\u001b[1;33m       new_state, new_inner_results = self.inner_kernel.one_step(\n\u001b[0m\u001b[0;32m    355\u001b[0m           current_state, inner_results, **inner_kwargs)\n\u001b[0;32m    356\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow_probability\\python\\mcmc\\hmc.py\u001b[0m in \u001b[0;36mone_step\u001b[1;34m(self, current_state, previous_kernel_results, seed)\u001b[0m\n\u001b[0;32m    547\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    548\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcontrol_dependencies\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mprevious_step_size_assign\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 549\u001b[1;33m       next_state, kernel_results = self._impl.one_step(\n\u001b[0m\u001b[0;32m    550\u001b[0m           current_state, previous_kernel_results, seed=seed)\n\u001b[0;32m    551\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstep_size_update_fn\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow_probability\\python\\mcmc\\metropolis_hastings.py\u001b[0m in \u001b[0;36mone_step\u001b[1;34m(self, current_state, previous_kernel_results, seed)\u001b[0m\n\u001b[0;32m    189\u001b[0m           \u001b[0mproposed_state\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    190\u001b[0m           \u001b[0mproposed_results\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 191\u001b[1;33m       \u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minner_kernel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mone_step\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    192\u001b[0m           \u001b[0mcurrent_state\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    193\u001b[0m           \u001b[0mprevious_kernel_results\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0maccepted_results\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow_probability\\python\\mcmc\\hmc.py\u001b[0m in \u001b[0;36mone_step\u001b[1;34m(self, current_state, previous_kernel_results, seed)\u001b[0m\n\u001b[0;32m    737\u001b[0m           \u001b[0mnext_target_log_prob\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    738\u001b[0m           \u001b[0mnext_target_log_prob_grad_parts\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 739\u001b[1;33m       \u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mintegrator\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcurrent_momentum_parts\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    740\u001b[0m                      \u001b[0mcurrent_state_parts\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    741\u001b[0m                      \u001b[0mcurrent_target_log_prob\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow_probability\\python\\mcmc\\internal\\leapfrog_integrator.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, momentum_parts, state_parts, target, target_grad_parts, kinetic_energy_fn, name)\u001b[0m\n\u001b[0;32m    289\u001b[0m           \u001b[0mnext_target\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    290\u001b[0m           \u001b[0mnext_target_grad_parts\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 291\u001b[1;33m       \u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwhile_loop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    292\u001b[0m           \u001b[0mcond\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mlambda\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0m_\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mi\u001b[0m \u001b[1;33m<\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnum_steps\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    293\u001b[0m           body=lambda i, *args: [i + 1] + list(_one_step(  # pylint: disable=no-value-for-parameter,g-long-lambda\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\util\\deprecation.py\u001b[0m in \u001b[0;36mnew_func\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    627\u001b[0m                   \u001b[0mfunc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__module__\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0marg_name\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0marg_value\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'in a future version'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    628\u001b[0m                   if date is None else ('after %s' % date), instructions)\n\u001b[1;32m--> 629\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    630\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    631\u001b[0m     doc = _add_deprecated_arg_value_notice_to_docstring(\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\control_flow_ops.py\u001b[0m in \u001b[0;36mwhile_loop_v2\u001b[1;34m(cond, body, loop_vars, shape_invariants, parallel_iterations, back_prop, swap_memory, maximum_iterations, name)\u001b[0m\n\u001b[0;32m   2514\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2515\u001b[0m   \"\"\"\n\u001b[1;32m-> 2516\u001b[1;33m   return while_loop(\n\u001b[0m\u001b[0;32m   2517\u001b[0m       \u001b[0mcond\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcond\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2518\u001b[0m       \u001b[0mbody\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mbody\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\control_flow_ops.py\u001b[0m in \u001b[0;36mwhile_loop\u001b[1;34m(cond, body, loop_vars, shape_invariants, parallel_iterations, back_prop, swap_memory, name, maximum_iterations, return_same_structure)\u001b[0m\n\u001b[0;32m   2763\u001b[0m                                               list(loop_vars))\n\u001b[0;32m   2764\u001b[0m       \u001b[1;32mwhile\u001b[0m \u001b[0mcond\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mloop_vars\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2765\u001b[1;33m         \u001b[0mloop_vars\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbody\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mloop_vars\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2766\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mtry_to_pack\u001b[0m \u001b[1;32mand\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mloop_vars\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_basetuple\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2767\u001b[0m           \u001b[0mpacked\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow_probability\\python\\mcmc\\internal\\leapfrog_integrator.py\u001b[0m in \u001b[0;36m<lambda>\u001b[1;34m(i, *args)\u001b[0m\n\u001b[0;32m    291\u001b[0m       \u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwhile_loop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    292\u001b[0m           \u001b[0mcond\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mlambda\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0m_\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mi\u001b[0m \u001b[1;33m<\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnum_steps\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 293\u001b[1;33m           body=lambda i, *args: [i + 1] + list(_one_step(  # pylint: disable=no-value-for-parameter,g-long-lambda\n\u001b[0m\u001b[0;32m    294\u001b[0m               self.target_fn, self.step_sizes, get_velocity_parts, *args)),\n\u001b[0;32m    295\u001b[0m           loop_vars=[\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow_probability\\python\\mcmc\\internal\\leapfrog_integrator.py\u001b[0m in \u001b[0;36m_one_step\u001b[1;34m(target_fn, step_sizes, get_velocity_parts, half_next_momentum_parts, state_parts, target, target_grad_parts)\u001b[0m\n\u001b[0;32m    334\u001b[0m       next_state_parts.append(\n\u001b[0;32m    335\u001b[0m           state_part + _multiply(eps, velocity_part, dtype=state_part.dtype))\n\u001b[1;32m--> 336\u001b[1;33m     [next_target, next_target_grad_parts] = mcmc_util.maybe_call_fn_and_grads(\n\u001b[0m\u001b[0;32m    337\u001b[0m         target_fn, next_state_parts)\n\u001b[0;32m    338\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0many\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mg\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mg\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mnext_target_grad_parts\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow_probability\\python\\mcmc\\internal\\util.py\u001b[0m in \u001b[0;36mmaybe_call_fn_and_grads\u001b[1;34m(fn, fn_arg_list, result, grads, check_non_none_grads, name)\u001b[0m\n\u001b[0;32m    295\u001b[0m     fn_arg_list = (list(fn_arg_list) if is_list_like(fn_arg_list)\n\u001b[0;32m    296\u001b[0m                    else [fn_arg_list])\n\u001b[1;32m--> 297\u001b[1;33m     \u001b[0mresult\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgrads\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_value_and_gradients\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfn_arg_list\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgrads\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    298\u001b[0m     if not all(dtype_util.is_floating(r.dtype)\n\u001b[0;32m    299\u001b[0m                for r in (result if is_list_like(result) else [result])):  # pylint: disable=superfluous-parens\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow_probability\\python\\mcmc\\internal\\util.py\u001b[0m in \u001b[0;36m_value_and_gradients\u001b[1;34m(fn, fn_arg_list, result, grads, name)\u001b[0m\n\u001b[0;32m    280\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgrads\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    281\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 282\u001b[1;33m     \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgrads\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtfp_math_value_and_gradients\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfn_arg_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    283\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    284\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgrads\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow_probability\\python\\math\\gradient.py\u001b[0m in \u001b[0;36mvalue_and_gradient\u001b[1;34m(f, output_gradients, use_gradient_tape, auto_unpack_single_arg, has_aux, name, *args, **kwargs)\u001b[0m\n\u001b[0;32m    106\u001b[0m   \"\"\"\n\u001b[0;32m    107\u001b[0m   \u001b[1;32mwith\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname_scope\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m \u001b[1;32mor\u001b[0m \u001b[1;34m'value_and_gradient'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 108\u001b[1;33m     return _value_and_grad_impl(\n\u001b[0m\u001b[0;32m    109\u001b[0m         \u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    110\u001b[0m         \u001b[0m_gradient_new\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexecuting_eagerly\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0muse_gradient_tape\u001b[0m \u001b[1;32melse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow_probability\\python\\math\\gradient.py\u001b[0m in \u001b[0;36m_value_and_grad_impl\u001b[1;34m(f, grad_fn, output_gradients, auto_unpack_single_arg, expand_tf_modules_as_trainable_vars, has_aux, *args, **kwargs)\u001b[0m\n\u001b[0;32m    376\u001b[0m                                  if _has_args(real_f) else real_f(), ())\n\u001b[0;32m    377\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 378\u001b[1;33m   y, dydx, aux = grad_fn(lambda: f(*args, **kwargs) if _has_args(f) else f(),\n\u001b[0m\u001b[0;32m    379\u001b[0m                          \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnest\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mexpand_args\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mexpand_kwargs\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    380\u001b[0m                          output_gradients)\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow_probability\\python\\math\\gradient.py\u001b[0m in \u001b[0;36m_gradient_new\u001b[1;34m(f, xs, grad_ys)\u001b[0m\n\u001b[0;32m    323\u001b[0m       \u001b[0mtape\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    324\u001b[0m     \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maux\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 325\u001b[1;33m   \u001b[1;32mreturn\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtape\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgradient\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mxs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moutput_gradients\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mgrad_ys\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maux\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    326\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    327\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\backprop.py\u001b[0m in \u001b[0;36mgradient\u001b[1;34m(self, target, sources, output_gradients, unconnected_gradients)\u001b[0m\n\u001b[0;32m   1110\u001b[0m                           for x in output_gradients]\n\u001b[0;32m   1111\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1112\u001b[1;33m     flat_grad = imperative_grad.imperative_grad(\n\u001b[0m\u001b[0;32m   1113\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_tape\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1114\u001b[0m         \u001b[0mflat_targets\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\imperative_grad.py\u001b[0m in \u001b[0;36mimperative_grad\u001b[1;34m(tape, target, sources, output_gradients, sources_raw, unconnected_gradients)\u001b[0m\n\u001b[0;32m     65\u001b[0m         \"Unknown value for unconnected_gradients: %r\" % unconnected_gradients)\n\u001b[0;32m     66\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 67\u001b[1;33m   return pywrap_tfe.TFE_Py_TapeGradient(\n\u001b[0m\u001b[0;32m     68\u001b[0m       \u001b[0mtape\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_tape\u001b[0m\u001b[1;33m,\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     69\u001b[0m       \u001b[0mtarget\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\backprop.py\u001b[0m in \u001b[0;36m_gradient_function\u001b[1;34m(op_name, attr_tuple, num_inputs, inputs, outputs, out_grads, skip_input_indices, forward_pass_name_scope)\u001b[0m\n\u001b[0;32m    155\u001b[0m       \u001b[0mgradient_name_scope\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mforward_pass_name_scope\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m\"/\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    156\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname_scope\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgradient_name_scope\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 157\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mgrad_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmock_op\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0mout_grads\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    158\u001b[0m   \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    159\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mgrad_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmock_op\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0mout_grads\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\array_grad.py\u001b[0m in \u001b[0;36m_StridedSliceGrad\u001b[1;34m(op, grad)\u001b[0m\n\u001b[0;32m    282\u001b[0m   \u001b[0mstrides\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mstrides_static\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mstrides_static\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32melse\u001b[0m \u001b[0mstrides\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    283\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 284\u001b[1;33m   return array_ops.strided_slice_grad(\n\u001b[0m\u001b[0;32m    285\u001b[0m       \u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    286\u001b[0m       \u001b[0mbegin\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\gen_array_ops.py\u001b[0m in \u001b[0;36mstrided_slice_grad\u001b[1;34m(shape, begin, end, strides, dy, begin_mask, end_mask, ellipsis_mask, new_axis_mask, shrink_axis_mask, name)\u001b[0m\n\u001b[0;32m  13681\u001b[0m   \u001b[1;32mif\u001b[0m \u001b[0mtld\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_eager\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m  13682\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m> 13683\u001b[1;33m       _result = pywrap_tfe.TFE_Py_FastPathExecute(\n\u001b[0m\u001b[0;32m  13684\u001b[0m         \u001b[0m_ctx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"StridedSliceGrad\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbegin\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mend\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstrides\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdy\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m  13685\u001b[0m         \u001b[1;34m\"begin_mask\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbegin_mask\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"end_mask\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mend_mask\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"ellipsis_mask\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "t0 = time.perf_counter()\n",
    "CAR_samples, chain_samples, sampler_stat = run_mcmc_CAR(init_state=init_state,\n",
    "                             target_log_prob_fn=target_log_prob_fn_CAR,\n",
    "                             debug_mode = True,\n",
    "                             **mcmc_config)  \n",
    "print(time.perf_counter() - t0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Saving and loading Python objects with Pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open('../data/CAR_samples_with_mat_determinant.pickle', 'wb') as results_file:\n",
    "  pickle.dump(CAR_samples, results_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(r\"../data/CAR_samples.pickle\", \"rb\") as input_file:\n",
    "     CAR_samples2 = pickle.load(input_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running MAP:\t13129634283520.0...13028767744.0...12917108736.0...12837866496.0...12796110848.0...12773912576.0...12757137408.0...12761999360.0...12907206656.0...13081935872.0...Done.\n",
      "Running MCMC:\tAcceptance Ratio: 0.6058999300003052\n"
     ]
    }
   ],
   "source": [
    "mcmc_nchain = 10\n",
    "\n",
    "# I can just run this first to get the code working. This way I can skip editing posterior_inference\n",
    "# and the prepare_mcmc and just focus on the log probability function\n",
    "CAR_samples, _ = run_mcmc(init_state=init_state,\n",
    "                             target_log_prob_fn=target_log_prob_fn,\n",
    "                             **mcmc_config)  \n",
    "\n",
    "bma_gp_w_samples = run_posterior_inference(model_dist=bma_prior, \n",
    "                                           model_config=bma_model_config,\n",
    "                                           Y=Y_train, \n",
    "                                           map_config=map_config,\n",
    "                                           mcmc_config=mcmc_config)\n",
    "\n",
    "\n",
    "bma_joint_samples = make_bma_samples(X_test1, Y_test, base_preds_test, \n",
    "                                     bma_weight_samples=bma_gp_w_samples[0],\n",
    "                                     bma_model_config=bma_model_config, \n",
    "                                     n_samples=bma_n_samples_eval, \n",
    "                                     seed=bne_seed,\n",
    "                                     y_samples_only=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['acs', 'pep', 'worldpop']"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "CAR_ensemble_weights = tf.reduce_mean(CAR_samples[0], axis = 2)\n",
    "\n",
    "weights_dict = {\n",
    "    \"acs\": CAR_ensemble_weights[:,0],\n",
    "    \"pep\": CAR_ensemble_weights[:,1],\n",
    "    \"worldpop\": CAR_ensemble_weights[:,2]\n",
    "}\n",
    "\n",
    "color_weights = make_color_norm(\n",
    "    list(weights_dict.values())[1],   \n",
    "    method=\"percentile\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get exponentiated values and sum across models\n",
    "exp_phi = tf.math.exp(CAR_ensemble_weights)\n",
    "exp_phi_rows = tf.reduce_sum(exp_phi, 1)\n",
    "\n",
    "# get model weights and calculate mean estimate\n",
    "u = exp_phi/exp_phi_rows[...,None]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "norm_weights_dict = {\n",
    "    \"acs\": u[:,0],\n",
    "    \"pep\": u[:,1],\n",
    "    \"worldpop\": u[:,2]\n",
    "}\n",
    "\n",
    "color_norm_weights = make_color_norm(\n",
    "    list(norm_weights_dict.values())[1],   \n",
    "    method=\"percentile\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly\n",
    "from urllib.request import urlopen\n",
    "import json\n",
    "with urlopen('https://raw.githubusercontent.com/plotly/datasets/master/geojson-counties-fips.json') as response:\n",
    "    counties = json.load(response)\n",
    "\n",
    "import pandas as pd\n",
    "# df = pd.read_csv(\"https://raw.githubusercontent.com/plotly/datasets/master/fips-unemp-16.csv\",\n",
    "#                    dtype={\"fips\": str})\n",
    "import matplotlib.colors as colors\n",
    "\n",
    "import plotly.express as px"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'counties' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[1;32mIn [53]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      3\u001b[0m output \u001b[38;5;241m=\u001b[39m output\u001b[38;5;241m.\u001b[39mset_axis([\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mGEOID\u001b[39m\u001b[38;5;124m'\u001b[39m, model_name], axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m      4\u001b[0m output[model_name] \u001b[38;5;241m=\u001b[39m output[model_name]\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;28mfloat\u001b[39m)\n\u001b[1;32m----> 5\u001b[0m fig \u001b[38;5;241m=\u001b[39m px\u001b[38;5;241m.\u001b[39mchoropleth_mapbox(output, geojson\u001b[38;5;241m=\u001b[39m\u001b[43mcounties\u001b[49m, locations\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mGEOID\u001b[39m\u001b[38;5;124m'\u001b[39m, color\u001b[38;5;241m=\u001b[39mmodel_name,\n\u001b[0;32m      6\u001b[0m                        color_continuous_scale\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mViridis\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m      7\u001b[0m                        \u001b[38;5;66;03m#range_color=(0.05,0.07),\u001b[39;00m\n\u001b[0;32m      8\u001b[0m                        mapbox_style\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcarto-positron\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m      9\u001b[0m                        \u001b[38;5;66;03m#featureidkey=\"properties.MWS_ID\",\u001b[39;00m\n\u001b[0;32m     10\u001b[0m                        zoom\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m3\u001b[39m, center \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlat\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;241m37.0902\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlon\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m95.7129\u001b[39m},\n\u001b[0;32m     11\u001b[0m                        opacity\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.5\u001b[39m,\n\u001b[0;32m     12\u001b[0m                        labels\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m'\u001b[39m\u001b[38;5;124munemp\u001b[39m\u001b[38;5;124m'\u001b[39m:\u001b[38;5;124m'\u001b[39m\u001b[38;5;124munemployment rate\u001b[39m\u001b[38;5;124m'\u001b[39m}\n\u001b[0;32m     13\u001b[0m                       )\n\u001b[0;32m     14\u001b[0m fig\u001b[38;5;241m.\u001b[39mupdate_layout(margin\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m:\u001b[38;5;241m0\u001b[39m,\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mt\u001b[39m\u001b[38;5;124m\"\u001b[39m:\u001b[38;5;241m0\u001b[39m,\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124ml\u001b[39m\u001b[38;5;124m\"\u001b[39m:\u001b[38;5;241m0\u001b[39m,\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m:\u001b[38;5;241m0\u001b[39m})\n\u001b[0;32m     15\u001b[0m fig\u001b[38;5;241m.\u001b[39mshow()\n",
      "\u001b[1;31mNameError\u001b[0m: name 'counties' is not defined"
     ]
    }
   ],
   "source": [
    "for model_name in models:\n",
    "    output = pd.DataFrame(np.column_stack([training2010[[\"GEOID\"]], weights_dict[model_name]]))\n",
    "    output = output.set_axis(['GEOID', model_name], axis=1)\n",
    "    output[model_name] = output[model_name].astype(float)\n",
    "    fig = px.choropleth_mapbox(output, geojson=counties, locations='GEOID', color=model_name,\n",
    "                           color_continuous_scale=\"Viridis\",\n",
    "                           #range_color=(0.05,0.07),\n",
    "                           mapbox_style=\"carto-positron\",\n",
    "                           #featureidkey=\"properties.MWS_ID\",\n",
    "                           zoom=3, center = {\"lat\": 37.0902, \"lon\": -95.7129},\n",
    "                           opacity=0.5,\n",
    "                           labels={'unemp':'unemployment rate'}\n",
    "                          )\n",
    "    fig.update_layout(margin={\"r\":0,\"t\":0,\"l\":0,\"b\":0})\n",
    "    fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'counties' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[1;32mIn [54]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      3\u001b[0m output \u001b[38;5;241m=\u001b[39m output\u001b[38;5;241m.\u001b[39mset_axis([\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mGEOID\u001b[39m\u001b[38;5;124m'\u001b[39m, model_name], axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m      4\u001b[0m output[model_name] \u001b[38;5;241m=\u001b[39m output[model_name]\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;28mfloat\u001b[39m)\n\u001b[1;32m----> 5\u001b[0m fig \u001b[38;5;241m=\u001b[39m px\u001b[38;5;241m.\u001b[39mchoropleth_mapbox(output, geojson\u001b[38;5;241m=\u001b[39m\u001b[43mcounties\u001b[49m, locations\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mGEOID\u001b[39m\u001b[38;5;124m'\u001b[39m, color\u001b[38;5;241m=\u001b[39mmodel_name,\n\u001b[0;32m      6\u001b[0m                        color_continuous_scale\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mViridis\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m      7\u001b[0m                        \u001b[38;5;66;03m#range_color=(0.05,0.07),\u001b[39;00m\n\u001b[0;32m      8\u001b[0m                        mapbox_style\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcarto-positron\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m      9\u001b[0m                        \u001b[38;5;66;03m#featureidkey=\"properties.MWS_ID\",\u001b[39;00m\n\u001b[0;32m     10\u001b[0m                        zoom\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m3\u001b[39m, center \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlat\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;241m37.0902\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlon\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m95.7129\u001b[39m},\n\u001b[0;32m     11\u001b[0m                        opacity\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.5\u001b[39m,\n\u001b[0;32m     12\u001b[0m                        labels\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m'\u001b[39m\u001b[38;5;124munemp\u001b[39m\u001b[38;5;124m'\u001b[39m:\u001b[38;5;124m'\u001b[39m\u001b[38;5;124munemployment rate\u001b[39m\u001b[38;5;124m'\u001b[39m}\n\u001b[0;32m     13\u001b[0m                       )\n\u001b[0;32m     14\u001b[0m fig\u001b[38;5;241m.\u001b[39mupdate_layout(margin\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m:\u001b[38;5;241m0\u001b[39m,\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mt\u001b[39m\u001b[38;5;124m\"\u001b[39m:\u001b[38;5;241m0\u001b[39m,\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124ml\u001b[39m\u001b[38;5;124m\"\u001b[39m:\u001b[38;5;241m0\u001b[39m,\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m:\u001b[38;5;241m0\u001b[39m})\n\u001b[0;32m     15\u001b[0m fig\u001b[38;5;241m.\u001b[39mshow()\n",
      "\u001b[1;31mNameError\u001b[0m: name 'counties' is not defined"
     ]
    }
   ],
   "source": [
    "for model_name in models:\n",
    "    output = pd.DataFrame(np.column_stack([training2010[[\"GEOID\"]], norm_weights_dict[model_name]]))\n",
    "    output = output.set_axis(['GEOID', model_name], axis=1)\n",
    "    output[model_name] = output[model_name].astype(float)\n",
    "    fig = px.choropleth_mapbox(output, geojson=counties, locations='GEOID', color=model_name,\n",
    "                           color_continuous_scale=\"Viridis\",\n",
    "                           #range_color=(0.05,0.07),\n",
    "                           mapbox_style=\"carto-positron\",\n",
    "                           #featureidkey=\"properties.MWS_ID\",\n",
    "                           zoom=3, center = {\"lat\": 37.0902, \"lon\": -95.7129},\n",
    "                           opacity=0.5,\n",
    "                           labels={'unemp':'unemployment rate'}\n",
    "                          )\n",
    "    fig.update_layout(margin={\"r\":0,\"t\":0,\"l\":0,\"b\":0})\n",
    "    fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "! conda install geopandas==0.3.0\n",
    "! conda install pyshp==1.2.10\n",
    "! conda install shapely==1.6.3"
   ]
  }
 ],
 "metadata": {
  "@webio": {
   "lastCommId": null,
   "lastKernelId": null
  },
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [
    "FyVOAW4EODnT",
    "ebzyBOEoNQ_a",
    "vAgjEq1-dty-"
   ],
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
